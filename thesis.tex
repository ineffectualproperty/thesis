\documentclass{article}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{relsize}
\usepackage{ifthen}
\usepackage{xstring}
\usepackage{cite}
\usepackage{placeins}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{bold-extra}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage[inline]{enumitem}
\usepackage{framed}
\usepackage{mathtools}
\usepackage{bm}

\include{dcr-preamble}
\include{msg-preamble}

\title{DCR/TEE \\
\large Working subtitle in a trusted execution environment}
\author{Mikkel Gaub \and Malthe Ettrup Kirkbro \and Mads Frederik Madsen}

% Allow line break at ',' in math mode:
% \makeatletter
% \def\old@comma{,}
% \catcode`\,=13
% \def,{%
%   \ifmmode%
% 	\old@comma\discretionary{}{}{}%
%   \else%
% 	\old@comma%
%   \fi%
% }
% \makeatother

% C++ command
\newcommand\cpp{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\relsize{-1}{\textbf{++}}}}

\begin{document}
\sloppy

\lstset{                       
  captionpos=b
 }

\lstdefinestyle{pseudo}{
  mathescape=true,
  morekeywords={function, send, to, receive, from, broadcast, unreceive, timeout, match, with, when, and, or, if, else},
  morecomment=[l]{//},
  keepspaces=true,
  basicstyle=\small\ttfamily,
  commentstyle=\color{darkgray},
  keywordstyle=\color{blue}\bfseries
}

\begin{titlepage}
	\maketitle
	\pagenumbering{gobble}

	\vspace{\fill}
	\begin{abstract}
		In this thesis the security and optimization options provided by recent advances in trusted execution environments (TEE), specifically Intel Secure Guard Extensions (SGX), are explored in relation to the problem of decentralized partial state replication.
		An algorithm, and the implementation of that algorithm, for running decentralized Dynamic Condition Response (DCR) graphs is used as the example of a system requiring decentralized replication.
		Lastly a description of what it would require to transform the developed system to be able to handle general smart contracts is given.
	\end{abstract}
\end{titlepage}

\clearpage
\pagenumbering{arabic}

\tableofcontents

\newpage

\section{Introduction}

	In a time where collaboration between companies, small and large, occurs daily across vast physical distances, a trusted means of coordination is key.
	An example of a means of coordination is Dynamic Condition Response (DCR) graphs, which is a declarative workflow management system.
	DCR graphs formulate processes in terms of events and relations between those events.
	The relations specify the order in which events can transpire, and what paths can be taken in the workflow.
	DCR graphs provide a concise and simple way of describing workflows, as executing an event can only affect events within a limited range, graph-wise.
	
	This property of limited effects on execution means that DCR graphs allow for highly localized states and depending on how a specific DCR graph is constructed, it can therefore allow for a very high degree of concurrency in a distributed setting.
	Central servers would be an easy solution to this problem, but would require trust and payment, due to a third party being involved and managing the process.
	An alternative to central servers is, of course, a decentralized solution, with participants acting as peers in a peer-to-peer network. 
	Decentralisation brings with it a completely different set of challenges, in that a core necessity of distributed collaboration is the agreement of all parties on what has transpired in the workflow and what the state of the workflow is at any given point, a non-trivial problem in decentralized DCR.
	This set of challenges is the problem we will present and solve during this thesis.
	
	As DCR graphs are concerned with maintaining a consistent state, the issue of making DCR graphs distributed is closely related to that of synchronizing distributed state replications.
	However, the innate properties of DCR graphs would be heavily constrained by existing solutions to distributed state replication, due to the large number of messages required and the low degree of concurrency provided by the strict synchronization of these algorithms.
	
	The problem, and solution, described in this thesis is not limited to applications of DCR, but can also be applied in other software concerned with maintaining a distributed, fragmented state.
	An example of such an application is also given, in the form of a distributed smart contract algorithm, as popularized by Ethereum \cite{_ethereum_2018}.

	Recent technological advances in the field of \textit{Trusted Execution Environments} (TEEs), specifically \textit{Intel Software Guard Extensions} (SGX) have already made waves within state replication solutions~\cite{kapitza_cheapbft_2012,veronese_efficient_2013,liu_scalable_2016} and could potentially be leveraged to provide a solution to the described problem, while achieving the goals of a low number of messages and a high degree of concurrency.
	Intel Software Guard Extensions (SGX), which provide a verifiable trusted subsystem to each participant, which is especially interesting in a decentralized system of mutually untrusting nodes.

	\noindent The contributions of this thesis are as follows:
	\begin{itemize}
		\item The design and implementation of a concurrent and fast distributed DCR engine, using SGX.
		\item A description of a generalized version of that design and implementation supporting arbitrary smart contracts rather than DCR graphs.
		\item An algorithm for achieving consensus in a decentralized and distributed state replication system, using less than $O(n)$ messages, where $n$ is the number of nodes in the network.
		\item An argument for trusted execution environment's ability to transform any crash stop tolerant algorithm to a byzantine failure tolerant one.
	\end{itemize}

	\subsection{Problem}
	The goal is a DCR engine with byzantine fault tolerance, that allows mutually untrusting actors to interact with the events in the graph to which they have execution rights.
	To achieve fault tolerance, the system must distribute the DCR graphs on several peers.

	Distributing DCR graphs is not a trivial problem, as there are considerations for the distribution of that graph, especially given the desire for a higher degree of concurrency than simply having all peers be responsible for the entire DCR graph.
	Alternatively, the DCR graph would have to be distributed on an event basis, but this is a much harder problem as changes only have to be propagated to the relevant events, meaning that multiple, possible conflicting, executions can happen simultaneously and would need synchronization intermittently.
	Actors interacting with the graph simultaneously should be allowed only when the ordering of those interactions is inconsequential.
	
	At any given time an actor should be able to collect the state of the graph and be ensured that any future state will not be incompatible with a previously collected state, with regards to the semantics specified by the graph.

	In summary, the system must:
	\begin{itemize}
		\item Support the replication of a decentralized DCR graph, while maintaining a high degree of concurrency as permitted by the specific DCR graph, as seen in~\cite{debois_concurrency_2015}.
		\item Achieve consensus on a state of a decentralized DCR graph in a number of messages by a factor of less than the number of nodes in the graph.
		\item Function in the presence of malicious workflow participants and network nodes, where the only guarantees are those based on strong cryptographic security.
	\end{itemize}   

	\subsection{Related works}

	An existing platform which partially provides a solution to the goal of this project is Ethereum~\cite{_ethereum_2018}.
	Ethereum is a distributed computing platform based on blockchain technologies, which does, however, also feature a currency, making computations disproportionately expensive, both monetarily and computationally due to the large amounts of computations required by proof-of-work based blockchains.
	Even though SGX is a new technology, it has already been proposed to solve several issues in the blockchain concept. 
	SGX has been used as an intermediate for faster consensus about transactions in~\cite{gopinath_nirmala_improving_2017}, however it still relies on the underlying blockchain to prevent double-spending.

	In~\cite{liu_scalable_2016} SGX has been utilized to implement a new Byzantine fault tolerance (BFT) consensus algorithm, called \textit{FastBFT}, which solves some of the scalability issues of blockchains.
	This is done by using the \textit{strawman design} where a request is sent to a node, the \textit{primary}, who prepares a vote by distributing parts of a secret to all nodes.
	The secret can be reconstructed given enough parts and then compared to the hash of the secret which is common knowledge.
	This means that consensus can be achieved in only $O(n)$ messages, rather than the $O(n^2)$ messages achieved by other algorithms.
	The reason that Intel SGX is needed for this algorithm is that the primary, who distributes the secrets, can fake being any node as he has all parts of the secret.
	Trusted Execution Environments (TEE) as introduced by Intel SGX, means that these secrets can be computed and distributed without the primary every having access to them.
	A further issue with the strawman design, is that the primary can change the orders of requests, thereby equivocate which request is being voted on.
	This is once again solved by Intel SGX, by numbering requests with a trusted counter that can only be incremented.

	In particular, the Hyperledger Sawtooth~\cite{dhillon_hyperledger_2017} project is interesting as it is closely related to the goals of our project.
	Hyperledger Sawtooth is an ongoing blockchain project, which replaces the need for mining by using a consensus algorithm called Proof of Elapsed Time (PoET).
	In PoET a number of nodes who choose to participate as validators each create a timer using Intel SGX.
	This timer is different per validator and contains a timestamp some time in the future, with a degree of randomness.
	A validator can also check that a timer is valid, using Intel SGX, and also whether or not that timer has expired.
	The first validator to distribute a valid and expired timer to the rest of the validators, is elected leader for the current round of decision-making.  
	This is a strong indicator that Intel SGX can be used for efficiently attaining consensus.

\section{Background}

% Description of components covered in this section and why they are needed.

	\subsection{DCR}
	\label{subsec:dcr}
	A DCR graph, $G$, is a graph representation of a workflow, made up of $v$ nodes, $E=\{e_1, e_2, \dots, e_v\}, v \geq 1$,  called \textit{events}, with a number of edges called \textit{relations} between them.
	Sometimes an event, $e$, in a graph, $G$, can be \textit{executed}, which will change the state and ability to execute of some events in $G$ according to the rules defined by $e$'s outgoing relations.
	We denote this execution $E(G,e)=G'$.

			\subsubsection{Event State}
			The events in a DCR graph have three binary attributes: \textit{included}, \textit{executed} and \textit{pending}. 
			This is an event: \ev{A}

			\begin{description}
				\item[Executed attribute] If an events \textit{executed} attribute is false executing the event will set its \textit{executed} attribute to true.
				Executing an already executed event will have no effect on the \textit{executed} attribute.
				The \textit{executed} attribute is shown as a tick mark: \ev[101]{A}
				\item[Pending attribute] If any event in a workflow has a \textit{pending} attribute that is true and the event is included, the workflow is in an unfinished state.
				Every time an event is executed its \textit{pending} attribute is set to false.
				This means that setting the \textit{pending} attribute of an included event to true is specifying that this event must be executed or excluded at some point to leave the workflow in a finished state.
				The \textit{pending} attribute is shown as an exclamation point: \ev[011]{A}
				\item[Included attribute] If the \textit{include} attribute of an event is false, the event is said to be excluded and it can not be executed.
				The \textit{included} attribute is denoted by the outline of the event: \ev{A} when included and \ev[000]{A} when excluded.
			\end{description}

			\subsubsection{Relations}
			\label{subsubsec:relations}
			There are five types of relations which define different types of relationships between events in a workflow.
			The origin and the target of a relation can be the same event.
			The five can be divided into two categories:

			\begin{description}
				\item[Effects] are relations that change the state of the targeted event. 
				If an effect originating from an event, \texttt{A}, is targeting an event, \texttt{B}, then \texttt{A} is said to be the effecting event on the effected event \texttt{B}.
				Effects are the \emph{response}, \emph{include} and \emph{exclude} relations. 
				\begin{description}
					\item[Response relation] If there is a response relation from event \texttt{A} to event \texttt{B}, then the \textit{pending} attribute of \texttt{B} will be set to true every time \texttt{A} is executed.
				The response relation is represented as: $\ev{A} \rrel \ev{B}$
					\item[Include relation] If there is an include relation from event \texttt{A} to event \texttt{B}, then the \textit{included} attribute of \texttt{B} will be set to true every time \texttt{A} is executed.
				The include relation is represented as: $\ev{A} \irel \ev{B}$
					\item[Exclude relation] If there is an exclude relation from event \texttt{A} to event \texttt{B}, then the \textit{included} attribute of \texttt{B} will be set to false every time \texttt{A} is executed.
				The exclude relation is represented as: $\ev{A} \erel \ev{B}$
				\end{description}
				\item[Constraint] are relations that exclusively affect whether or not the targeted event can be executed. 
				If a constraint originating from an event, \texttt{A}, is targeting an event, \texttt{B}, then \texttt{A} is said to be the constraining event on the constrained event \texttt{B}.
				Constraints are the \emph{condition} and \emph{milestone} relations. 
				\begin{description}
					\item[Condition relation] If there is a condition relation from event \texttt{A} to event \texttt{B}, then \texttt{B} can only be executed if the \textit{executed} attribute of \texttt{A} is true or the \textit{included} attribute of \texttt{A} is false.
				The condition relation is represented as: $\ev{A} \crel \ev{B}$
					\item[Milestone relation] If there is a milestone relation from event \texttt{A} to event \texttt{B}, then \texttt{B} can only be executed if the \textit{pending} attribute of \texttt{A} is false or the \textit{included} attribute of \texttt{A} is false.
				The milestone relation is represented as: $\ev{A} \mrel \ev{B}$
				\end{description}
			\end{description}

			\subsubsection{Enabledness}
			Since the properties of DCR graphs described so far all affect whether or not a given event can be executed or not, we use the notion of enabledness to describe the sum of these properties.
			An event which can be executed, meaning it is included and any milestones or conditions targeting it are rendered invalid by the state of the relevant events, it is said to be enabled.
			If an event cannot be executed, due to the inverse of the aforementioned prerequisites, it is said to be disabled.
			If an event changes from being enabled to disabled or from disabled to enabled, its enabledness is said to have changed.
			We define an execution of a disabled event as $E(G,e_1) = G$, i.e. no events changes state nor enabledness, not even $e_1$ itself.

			%ADD SOME EXECUTION FORMALIZATION AND DEFINITION OF RUN AS EXECUTION SEQUENCE
			\subsubsection{Formalising \texorpdfstring{$G$}{}}
			After the previous definitions, we can now formalise the concept of a DCR graph $G$:
			$G = (E, I, P, Ex, En, R)$, where
			\begin{itemize}
				\item $E$ is the set of all events.
				\item $I \subseteq E$ is set of the included events.
				\item $P \subseteq E$ is the set of pending events.
				\item $Ex \subseteq E$ is the set of excluded event.
				\item $En \subseteq E$ is the set of enabled events.
				\item $R = \{r_1, r_2, \dots r_e\}$ is the set of relations, where each relation, $r$, has the form $r=(e_{from}, e_{to}, Type)$ and $e_{from}$ is the event for which $r$ is directed from, $e_{to}$ is the event for which $r$ is directed to, and $Type$ is one of the relation typed described in section~\ref{subsubsec:relations}.
			\end{itemize}

			If, in a given state of $G$, an event $e$ changes state or enabledness if event $e'$ is executed, we say that $e$ is in $e'$s \textit{effecting event set}, denoted $E_{eff}(G,e')$. 

			\subsubsection{Concurrency}
			\label{subsubsec:concurrency}

			The notion of concurrency in DCR graphs, described in~\cite{debois_concurrency_2015}, is the property a pair of events is said to have when the graph allows those events to be executed in either order with the same resulting state in graph.

			More formally, given a graph, $G$, and two events $e_1, e_2$ in $G$, we say that $e_1$ and $e_2$ are concurrent if $E(E(G, e_1),e_2)=E(E(G, e_2),e_1)$.

			If two events are concurrent, we say that they are independent.
			There are two types of independence analyses relevant for this thesis:
			\begin{description}
				\item[Dynamic independence] means that for two given events and their current state, are they independent.
				That is, $e_1$ and $e_2$ are dynamically independent if $E(E(G, e_1),e_2)=E(E(G, e_2),e_1)$ for the current $G$.

				We say that an event, $e$, has a \textit{dynamic independence set}, $I_{dyn}(G,e)$, such that $e' \in I_{dyn}(G,e)$ iff. $e$ and $e'$ are dynamically independent in graph state $G$.
				Likewise an event, $e$, has a \textit{dynamic dependence set}, $D_{dyn}(G,e) = E \setminus I_{dyn}(G,e)$.

				% Notice that the dynamic dependence set is closely related to effecting event set of an event s.t. $e' \in D_{dyn}(G,e) \implies e \in E_{eff}(G,e') \lor e' \in E_{eff}(G,e)$, i.e.  if $e'$ is in the dynamically dependence set of $e$ then then either the execution of $e$ changes the state or the enabledness of $e'$, or the execution of $e'$ changes the state or the enabledness of $e$.

				\item[Static independence] means that two events, are dynamically independent in every \textit{reachable} state of the graph, where they are both enabled.
				That is, $e_1$ and $e_2$ are statically independent in $G$, if they are dynamically independent in all states of $G$ that can be reached by a run. %explain run

				We say that an event, $e$, has a \textit{static independence set}, $I_{stat}(e)$, such that $e' \in I_{stat}(e)$ iff. $e$ and $e'$ are statically independent.
				Likewise an event, $e$, has a \textit{static dependence set}, $D_{stat}(e) = E \setminus I_{stat}(e)$.
				Notice that $e$s static dependence set is the set of events that are dependent with $e$ in \textit{some} state of $G$, not all.
				This problem is NP-hard and an approximation will have to be used instead~\cite{debois_concurrency_2015}.
			\end{description}

			The approximation we use of static event independence is from~\cite{debois_concurrency_2015}, and boils down to the following principles, where we say that $e_1$ and $e_2$ are approximately statically dependent if, in any event-state permutation of $G$: %forklar event-state permutation?
			\begin{itemize}
				\item $e_1$ can enable $e_2$, and vice versa.
				\item $e_1$ can disable $e_2$, and vice versa.
				\item $e_1$ can disable some $e$, if $e_2$ can enable it, and vice versa.
				\item $e_1$ can exclude some $e$, if $e_2$ can include it, and vice versa.
				\item $e_1$ can set $e_2$ to pending, unless $e_2$ sets itself to pending, and vice versa.
			\end{itemize}
			This approximation is sound, but incomplete, which means that it contains all statically dependent event pairs, but does not guarantee that an event pair in the approximation is not statically independent.

			We say that an event, $e$, has an \textit{approximate static dependence set}, $D_{appr}(e)$, such that $e' \in D_{appr}(e)$ iff. $e$ and $e'$ are approximately statically dependent, according to the above approximation.
			Likewise an event, $e$, has an \textit{approximate static independence set}, $I_{appr}(e),  = E \setminus D_{appr}(e)$.

			All the independence- and dependence sets are reflexive: $e' \in S(e) \iff e \in S(e')$, where $S$ is any of the described (in-)dependency sets.


			Notice that in any DCR graph it must hold that $\forall G. \forall e. I_{dyn}(G,e) \geq I_{stat}(e) \geq I_{appr}(e)$, which speaks to the desirability of the different concurrency levels; a system that supports concurrent execution of dynamically independent events allows for more concurrent executions than a one that supports execution of statically independent events, which in turn allows for more concurrent executions than one that supports execution of approximate statically independent events.

			Figure~\ref{fig:concurrency-all} shows examples of independence in DCR graphs.

		\begin{figure}[!ht]
			\center
			\includegraphics[scale=0.6]{figures/dcr-graphs/concurrency-all.pdf}
			\caption{From top to bottom:
			(1) An example of a DCR graph where \ev{A} and \ev{B} are not concurrent.
			(2) An example of a DCR graph where \ev{A} and \ev{B} are statically independent.
			(3) An example of a DCR graph where \ev{A} and \ev{B} are dynamically, but not statically independent.
			(4) An example of a DCR graph where \ev{A} and \ev{B} are statically independent, but the approximation will contain them as a dependent pair\label{fig:concurrency-all}.}
		\end{figure}

			% Independent exec: ændrer til det samme, eller ikke rører ved ? 
			% Independent enab: Læser ikke hvad du skriver ? 
			% Backwards og forwards validation ? 

			\subsubsection{Execution rights}
			For DCR graphs to have a meaningful application, each event is typically assigned a number of actors who are allowed to execute that event.
			Rights to execute can also be assigned based on role.



		\subsection{Consensus}
		\label{subsec:consensus}
		Consensus is the problem of achieving agreement between the processes in a distributed system. 
		It is central to the the problem of distributed DCR, as agreement on the states of event must be achieved to ensure that all correct peers adhere to the semantics of the DCR graph. 
		Take the simple graph $\ev{A} \crel \ev{B}$, and let a subset of peers $p_1$ be responsible for the state of $\ev{A}$, and a subset of peer $p_2$ be responsible for the state of $\ev{B}$.
		If agreement on the state of $\ev{A}$ is not guaranteed, then $p_2$ might, in the belief that $\ev{A}$ is executed, execute $\ev{B}$ even though $p_1$ has never executed $\ev{A}$. 

		A consensus protocol is formally as a protocol with $N$ processes ($p_0, p_1, \dots, p_{N-1}$), where each process $p_i$ begins in an undecided state, and proposes a single value $v_i$ from a set of values $D$. The processes then communicate their values to each other, and each process sets a decision variable $d_i$ and enters a decided state. For the protocol to solve the consensus problem, the following requirements should hold for every execution:
		\begin{description}
			\item[Termination:] every process eventually sets its decision variable.
			\item[Agreement:] the decision variable of all correct processes are the same.
			\item[Validity:] if a correct process decides $d$, then some correct process has proposed a value $v$, where $v = d$.
		\end{description}

		It's easy to see that distributed DCR reduces to consensus.
		The reduction without any concurrency goes like this:\\
		\noindent
		We assume that the correct graph has been distributed to all peers, and initial state is agreed upon.
		\begin{itemize}
			\item Let $D$ be the set of enabled events.
			\item Let $v_i$ be an identifier an event. 
			\item A correct process will only propose $v_i$ if the event identified by $v_i$ is enabled.
			\item We can now use a consensus sub-process to decide on a $v$, which will then be executed.
			\item Each process recalculates $D$ to reflect the new global state, and repeats the protocol until the workflow has been completed.
		\end{itemize}

		In the famous FLP impossibility result from 1985~\cite{fischer_impossibility_1985}, it was shown that non-termination was possible in all consensus protocol systems with asynchronous communication channels and at least one (crash)faulty process.
		In order to circumvent this impossibility, the guarantees of a fault-tolerant system that utilizes a consensus protocol are relaxed, for instance by guaranteeing Termination only when no faults are present, as is the case in  the Paxos protocol~\cite{lamport_part-time_1998}. 

		\subsubsection{State Machine Replication}
		One problem that relates directly to consensus, is \textit{State Machine Replication} (SMR)~\cite{schneider_implementing_1990}.
		SMR is the problem of replicating the state of a system on several nodes, called \textit{replicas}.
		Replicas are each running an instance of the same state machine, and must take requests and pass them on to the state machine.
		In SMR systems, \textit{clients} send requests to replicas who must then guarantee:
		\begin{description}
			\item[Safety:] all non-faulty replicas execute the requests in the same order.
			\item[Liveness:] clients eventually receive replies to their requests.
		\end{description}
		The state machine replication problem is equivalent to the consensus problem and essentially provides the same guarantees~\cite{schneider_implementing_1990}, since a solution to SMR is consensus on a request log. 
		This is evident in the fact that the safety requirement is essentially an aggregation of the agreement and validity requirements in consensus, while the liveness property is equivalent to termination.  
		As such, FLP impossibility entails that one of the requirements must be relaxed in fault tolerant SMR systems.
		This is often done by only guaranteeing liveness when no failures are present.

		A version of SMR deals with byzantine faults, instead of crash failures.
		These systems are knowns as \textit{byzantine fault tolerance} (BFT) systems.
		These systems deals with arbitrary faults, that is arbitrary behaviour of faulty processes and channels, including changing messages, creating new messages and changing local state. 
		It has been shown that $2f+1$ processes are necessary and sufficient to solve SMR with relaxed liveness if faulty processes only exhibit crashes~\cite{bracha_asynchronous_1985}. 
		Similarly it has been shown that $3f+1$ processes are necessary and sufficient to solve SMR with relaxed liveness if faulty processes can exhibit byzantine faults~\cite{bracha_asynchronous_1985,pease_reaching_1980}.
		Recent advances have been made in BFT-algorithms, which increase fault tolerance from $3f+1$ to $2f+1$ by utilizing TEE features~\cite{liu_scalable_2016,kapitza_cheapbft_2012,veronese_efficient_2013}.
		When we take the proofs of sufficient and necessary amounts of processes in BFT systems into account, these advanced strongly indicates that TEEs might be able to reduce byzantine faults to crash faults, a statement we will explore further in section \ref{sec:transforming-byzantine-faults}.
		SMR brings with it the taxing job of pushing each update to all nodes in the network, which leads to obvious scalability issues in large networks.

		One solution to that problem is delegating the responsibility of segments of data to each node in the network.
		This is called \textit{Partial State Machine Replication} (PSMR).
		PSMR, by necessity, allows multiple simultaneous leaders and only synchronizes state changes when those state changes are conflicting.
		Due to allowing multiple leaders, PSMR provides high availability as any node can request a state change.
		High concurrency and performance also follows from the partial states reducing the number of nodes which have to be notified of a state change leading to both fewer messages and less chance of two state changes overlapping, requiring ordering.
		Relatively few solutions exists for the PSMR problem and the ones that do require a large amount of messages \cite{sousa_partial_2001}.
		To the best of our knowledge, no solution to the PSMR problem using a trusted execution environment exists.

		\subsection{Intel Software Guard Extensions}
		SGX is a TEE technology which includes a set of CPU instructions, that allows user-level code to define and run in protected areas of memory, so called \textit{enclaves}.
		Only processes running in enclaves are allowed to access the SGX instructions.
		Intel guarantees~\cite{intel_sgx} that any code run and data loaded in the enclaves is protected from access by any process running outside of the enclave.
		More specifically, the guarantees encompass \textit{confidentiality}, only the process running in the enclave can read the contents of the enclave, and \textit{integrity}, only the process running in the enclave can modify the contents of the enclave.
		These guarantees of the enclave comes at the expense of access to system calls, and by extension, hardware peripherals.
		Any code running in an enclave is therefore unable to access, for instance, hard disks, network cards and the console.
		As such, an enclave that requires system calls must have a so-called \textit{wrapper component} which is a non-enclave process that make calls to, and receive calls from enclaves processes.  

		This is all made possible by a set of unique keys generated during manufacturing and permanently stored inside the so-called \textit{fuse array} of the processor -- an array of fuses that can be programmed once and then closed for further programming~\cite{robson_electrically_2007}.
		Using these keys, an enclave process is able to identify if another process is an enclave process, using the process of \textit{local attestation}.
		This process can be extended to identify if a process running on another processor is an enclave process, by contacting Intel's servers for verification of the other processor's key.
		As such, some of the keys are known by Intel for the system to be recognized when contacting Intel servers.

		In short, the major innovation in Intel SGX is the option of running hardware secured software, which enables tamper proof messages, where the sender can be verified as being a correct process.

			\subsubsection{Enclave}
			\label{subsec:enclave}
			What allows SGX enabled CPUs to provide these strong guarantees of confidentiality and integrity builds on the following two hardware details:
			\begin{description}
				\item [Processor Reserved Memory (PRM)] is a sequential block of memory reserved for SGX, only accessible through enclave CPU instructions.
				\item [Enclave mode] is a mode under which a process gains access to the PRM.
			\end{description}
			Using these hardware facilities SGX defines the concept of an enclave.
			An enclave is a software module which, as its name suggests, is isolated completely from the rest of the system.
			Its memory is located solely in PRM, preventing access by other processes and enclaves running on the system. 
			The PRM is protected from non-enclave processes by enclave mode. 
			When a process is not in enclave mode and tries to access the PRM, the memory access is denied by the processor~\cite{costan_intel_2016}.      
			The PRM of an enclave process is protected from accesses by other processes in enclave mode by the SGX Enclave Control Structure (SECS). 
			The SECS holds meta data about the enclave processes, and among this is a virtual-to-physical memory mapping called the Enclave Page Cache (EPC). 
			Through the EPC an enclave's access to physical PRM is restricted to what has been allocated for the enclave-process~\cite{costan_intel_2016}.

			While SGX provides powerful guarantees trough its enclave concept, it does not guarantee software correctness and will not protect against flawed software.
			Instead SGX encourages developers to isolate a minimal piece of their software, the Trusted Computing Base (TCB), in a trusted enclave environment, and keep the remainder as traditional system processes~\cite{intel_sgx_guide}.
			By minimizing the size of the TCB, and thus the amount of code one must trust, common security principles dictate that the chance of security flaws decreases~\cite{intel_sgx_guide}.

			In order for an isolated enclave to be useful, communication between trusted and untrusted software is enabled through \textit{enclave calls} (ECALL) and \textit{out calls} (OCALL).
			This interface must be defined at compile-time, specifying an API of ECALLs for the enclave as well as any untrusted services needed as OCALLs, in a \textit{EDL}-file~\cite{intel_sgx_guide}.

			When built, an enclave module is a plain binary on the untrusted file system.
			As an enclave under such circumstances would be vulnerable to tampering before initialization, SGX enforces a strict signature policy.
			An enclave must include an \textit{Enclave Signature} containing \textbf{(a)} a hash of the code and initialization data of the enclave, \textbf{(b)} the author's public key and \textbf{(c)} an enclave version/product number.
			During enclave initialization a hardware check is performed, ensuring the Enclave Signature matches the enclave binary loaded from the file system.
			This signature identifies the enclave during the attestation process as well, so if an adversary were to tamper with an existing enclave binary, the contents would no longer match, and would not be allowed to be loaded by SGX, and if the adversary were to create their own enclave, the signature would no longer match, and would then be rejected if it tried to do attestation with another uncorrupted enclave.

			Another powerful tool of an SGX enclave is the ability to read from and write data to an untrusted storage medium while ensuring confidentiality of its contents.
			Such capabilities are needed as the PRM is volatile and will not persist after shutdown.
			In SGX this process is known as \textit{sealing}.
			Sealing allows encryption and decryption using a \textit{Seal Key}, which is confidential to the Enclave Signature.

			However, these mechanics alone does not guarantee integrity, as integrity is not only violated by other processes.
			For instance, the infamous Single Upset Event (also knowns as cosmic ray bit flips)~\cite{normand_single_1996}, is an integrity violation where bits in memory are flipped due to background radiation. 
			Intel SGX protects against such hardware errors by using cryptographic integrity checks~\cite{gueron_memory_2016}.
			When loading enclave memory, Intel SGX's Memory Encryption Engine (MEE) decrypts the memory, and then performs an integrity check on the loaded memory.
			If the integrity check does not pass, the processor drops the memory, and eventually locks itself for further operations (the \textit{drop-and-lock policy}), requiring a physical reset before new operations can be completed~\cite{jang_sgx-bomb_2017}.

			The integrity checks is implemented as a Merkle-Tree of Message Authentication Codes (MACs), with the root node of the tree stored on processor-internal memory~\cite{jang_sgx-bomb_2017}. 
			Under the assumption that AES128 is a random permutation, this method provides the guarantee that an active adversary with the capability of observing the MACs has a negligible probability of forgery~\cite{gueron_memory_2016}.

			A practical example of the effectiveness of this integrity check is the \textit{SGX bomb} attack~\cite{jang_sgx-bomb_2017}. 
			The SGX bomb, is a denial-of-service attack on Intel SGX. 
			It utilises a Row hammer attack to flip arbitrary bits in the EPC, thus triggering the drop-and-lock policy when memory is loaded.

			\subsubsection{Attestation}
			\label{subsec:attestation}
			Attestation, within the Intel SGX platform, is the action of verifying that some other process is running inside a specific enclave.
			The applications of this are two-fold, in the case where there are multiple enclaves running locally on the same CPU and in the case where enclaves need to communicate to enclaves running on external CPUs.
			These two situations are handled by two different processes, aptly named local and remote attestation.
	  
			Local attestation builds on a secret fused into the CPU.
			An enclave can use an SGX instruction to generate a \textit{report} uniquely identifying the enclave, the enclave signature among them.
			This report is MACed with a key derived from the fused secret and enclave identifier.
			It is not possible to fake such a MACed report, as the MACing happens in hardware components that ensure that the report corresponds to the caller enclave.
			The fused secret is not directly accessible by software components, but can only be used by certain hardware instructions that protect against malicious use~\cite{costan_intel_2016}.
			An attestation challenger will ask for a MACed report from the client enclave, and after receiving it derive the same key to verify the MAC.
			Because a report can only be created by the enclave it describes, the challenger can be certain of which enclave the client is running if the MAC is valid.
			To prevent replays the MACed report is allowed to contain a block of arbitrary data, in which the challenger can require a nonce~\cite{costan_intel_2016}.

			Remote attestations build on the same concept of a report, but as challenger and client are now on different CPUs, they no longer hold the same fused secret.
			Instead remote attestation relies on the group signature scheme Enhanced Privacy ID (EPID) and a third party issuer.
			Each SGX enabled CPU is granted an EPID Member Private Key by the third party issuer some time after manufacturing.
			Like the fused secret, this private key is not directly accessible to an enclave~\cite{costan_intel_2016}.
			Under the EPID scheme, all issuer generated private keys share the same public key (EPID Group Public Key).
			When remote attestation takes place, the client enclave generates a report and attests locally with the Quoting Enclave (QE).
			The QE, now convinced of the client enclave's identify, strips the MAC off the report and instead signs it with the EPID Member Private Key, which the QE has special privileges to access\footnote{Enclaves signed by Intel have special privileges throughout SGX. This allows SGX to implement complicated SGX instructions in software.}.
			The remote challenger can verify the signed report with the EPID Group Public Key and be sure that \textbf{(a)} the report is signed by an EPID Member Private Key, \textbf{(b)} EPID Member Private Keys are granted secret to QEs, and \textbf{(c)} QEs will not sign false reports~\cite{costan_intel_2016}.

			%TODO, Mangler, sdf: Præcis beskrivelse af remote attestation process. 

			\subsubsection{Monotonic counters}
			One of the functions provided by Intel SGX, which is especially relevant for this project, is the access to \textit{trusted monotonic counters}.
			As indicated by the name, monotonic counters are integer counters, that can only be incremented.
			They are implemented as a block of non-volatile memory accessible only through SGX instructions, protecting against replay attacks.

	\section{System model}
	We consider a system of $n$ processes $P=\{p_1, p_2, \dots, p_n\}$, that communicate through message passing channels.
	The system is asynchronous, in the sense that we make no assumptions about the execution speed of processes, or delivery time of messages.

	We assume a byzantine fault model, in that processes may fail by exhibiting arbitrary behaviour, except %for enclave components which can only exhibit crash-failures because of the integrity and confidentiality guarantees given by Intel SGX.
	%We also assume
	that byzantine faults cannot guess or simulate our cryptographic secrets.
	%corrupt data that has been cryptographically signed or encrypted by an enclave, in such a way that the data is still correctly signed/encrypted by the same key after the data has been corrupted.
	Byzantine faults includes, but are not limited to, crashes and arbitrary change of local state.
	Processes that never fail are \textit{correct}, and processes that are not correct are \textit{faulty}.
	% Notice that after section \ref{sec:transforming-byzantine-faults} we will only consider crash-faults, due to the argument that Intel SGX can, in a system where faulty processes can exhibit byzantine faults, make correct processes exhibit behaviour equivalent to the faulty processes being crashed.

	% The system includes a DCR-graph, $G$, which consists of $v$ events $E = \{e_1, e_2, \dots, e_v\}$. %, such that $n > m$. %\geq 3m$??? 
	% Each $p$ stores the state of a subset of the events, $E_p$, such that $E_{p_1} \cup E_{p_2} \cup \dots \cup E_{p_n} = E$.
	% The number of $p$s that stores an $e$'s state is the \textit{replication factor} of $e$, denoted $\rho_e$.
	% $E_{p_1} \cup E_{p_2} \cup \dots \cup E_{p_n} = E \implies \rho_e \geq 1$, for all $e$.
	% Or in other words, each event's state is stored on at least 1 $p$. 

	% We will assume that if $p_e$ stores the state of $e$, then $p_e$ has a channel to all $p$s that stores the state of $e$'s approximate static dependence set, $D_{appr}(e)$.


	\section{Transforming byzantine faults to crashes}
	\label{sec:transforming-byzantine-faults}
	We conjecture that the correct use of Intel SGX can transform all byzantine faults in a distributed system with unreliable channels, such that correct processes in the protocol treat faulty processes as equivalent to processes crashing and losing messages. 

	Thereby a crash-fault-tolerant distributed protocol with unreliable channels which will exhibit undocumented behaviour under byzantine-faults (from here on in "crash-resistant protocol") can be transformed into a byzantine-fault-tolerant protocol using Intel SGX and cryptography.
	We assume that processes exhibiting byzantine faults will not be able to utilize the cryptographic secrets of a correct process.

	\begin{figure}[!ht]
		\center
		\includegraphics[scale=0.6]{figures/state-machines/simple-NFA.pdf}
		\caption{A simple example of our finite state machine model\label{fig:simple-nfa}}
	\end{figure}

	To show the transformation, we will model an arbitrary distributed protocol as consisting of \textit{finite state machines}, \textit{channels} and \textit{processes}.
	A finite state machine consists of a current state, $s_{current}$, a finite set of $n$ distinct states, $S=\{s_1, s_2, \dots, s_n\}$, and a finite set of $m$ distinct state-transitions, $T$.
	A finite state machine can only be in one state at any time, and transitions to another state by accepting a bit-string as input, and optionally outputs another bit-string. 
	A transition has the form $(s_{from}, i, o, s_{to})$, where $i$ is an input consisting of a tuple of a bit-string and the channel the bit-string was received on, and $o$ is the output consisting of a set of bit-string/channel pair, each representing that bit-string being sent on the appertaining channel.
	For example, the finite state machine in Figure \ref{fig:simple-nfa} will transition from the starting state $s_0$ to $s_2$ on input $"010"$ from channel $c_0$, and will during the transition output $"101"$ to channel $c_1$ and $"100"$ to $c_2$.
	
	A channel can either be reliable or unreliable, and is bi-directional. 
	A reliable channel guarantees that messages sent on it will be delivered in the order the messages was sent, and will not be changed during transmission.
	An unreliable channel gives no such guarantees, and can thus experience loss, reordering and corruption of messages.

	The last component in our model is the process.
	A process is a set of running state machines.
	The state machines inside the process can be connected with reliable channels. 
	State machines can be connected to state machines in other processes only with unreliable channels.

	\begin{figure}[ht]
		\center
		\includegraphics[scale=0.6]{figures/state-machines/Distributed-protocol-model.pdf}
		\caption{A simple example of distributed protocol model.\label{fig:simple-model}}
	\end{figure}

	Figure \ref{fig:simple-model} is a model of a simple distributed protocol, consisting of the processes $P_0$ and $P_1$, each of which has three state machines $SM_0 - SM_5$. 
	Each state machine is connected to other state machines on the same process with reliable channels $c_0-c_3$, and $SM_1$ on $P_0$ is connected to $SM_3$ on $P_1$ with the unreliable channel $c_4$.

	A distributed protocol can experience a plethora of different errors. 
	Apart from the channel faults already described, we will model crashes and byzantine faults, as these are the ones we are concerned about in this transformation.
	We model a crash fault in the state machine by adding an empty input transition ("$\epsilon$") from every state to an error-state, which cannot transition to another state (see $s_{error}$ in Figure \ref{fig:simple-nfa}).
	As the state machine will not be able to transition to another state, and thus also cannot output anything from this state, this serves to model a component crashing in distributed protocol.
	We model a byzantine fault by exchanging a process with a new process.
	This potentially includes the removal of state machines, the addition of state machines or the exchange of old state machine with new state machines with new current states and new channels (we will refer to this last case as \textit{corrupted} state machines).
	This models a process beginning to exhibit arbitrary behaviour.

	To transform a crash-resistant distributed protocol into a byzantine-fault-tolerant protocol, we utilize the verification in Remote Attestation (see section \ref{subsec:attestation}) and the integrity guarantees provided by Intel SGX.
	To model the integrity guarantees, we introduce the notion of a cryptographic secret state machine $SM_{s}$, and an integrity protected area of the process.
	We assume that any byzantine fault can replicate $SM_{s}$, but cannot replicate the secrets contained in $SM_s$ if $SM_s$ is changed. 
	This models that faulty processes cannot access the cryptographic secrets of a correct process, which is a reasonable assumption by the integrity and confidentiality guarantees given by Intel SGX, given that the secrets are stored in an enclave (see section \ref{subsec:enclave}).
	State machines running in the integrity protected area of the process can be uniquely identified by $SM_{s}$, but cannot have channels to state machines running on other processes.
	This models the integrity protection in Intel SGX and the QE' abilities, as well as an enclave's inability to access peripheral hardware such as network cards.

	To model the Remote Attestation verification, we introduce a Remote Attestation process, $P_{RA}$ and an Attestation state machine, $P_A$, which will communicate with $P_{RA}$ to verify and provision $SM_s$ with a symmetric secret key.
	We will not go into detail with, or model the protocol used by, the Remote Attestation protocol, and just use it at an abstract for readability.
	For more information on the Remote Attestation protocol, see section \ref{subsec:attestation}, \textit{Intel SGX explained}~\cite{costan_intel_2016} and/or \textit{Intel SGX Developer guide}~\cite{intel_sgx_guide}.

	We will also assume that each process has a process unique identifier, $id_p$, that $SM_s$ knows $id_p$, and that each untransformed state machine includes both this $id_p$ and the $id_p$ of the intended receiver it's outgoing messages.
	In the case of broadcast messages, the $id_p$ of the receiving processes can be omitted. 
	In practise, this could be implemented as a process's external IP-address that is provisioned to $SM_s$ by in a verifiable or trusted manner (for instance by $P_{RA}$ during secret provisioning), or by a sufficiently large number that is randomly selected on process start up.
	Both of these solutions require a handshake protocol during channel establishment, in which $SM_s$ on each process must MAC their $id_p$ with the Remote Attestation provisioned secret for verification by the other process. 
	We will not describe this handshake protocol.

	The transformation from a crash-resistant protocol to a byzantine-fault-tolerant protocol consist of 4 steps on the process-level:
	\begin{enumerate}
		\item Add all the state machines to the integrity protected area of the process.
			\begin{itemize}
				\item This is equivalent to making the distributed components in the crash-resistant protocol into enclaves. 
				Please note that it is rarely necessary to integrity protect all components.
				Instead the minimal necessary number of components, the TCB, should be identified and integrity protected.
				For the general case, however, every component is part of the TCB.
			\end{itemize}
		\item For each endpoint state machine in unreliable channels between processes, add a new state machine in the unprotected area of each of the processes (called a wrapper state machine), connect a new unreliable channel between these and add a reliable channel from the old endpoint state machines to the new.
			\begin{itemize}
				\item This is equivalent to adding unprotected wrapper components for the enclaves, which will have access to the network, an thus can act as a middle-man for communicating with other processes.
			\end{itemize}
		\item Add reliable channels from all state machines in the integrity protected area of the process to the cryptographic secret state machine $SM_s$.
		\item Add an Attestation state machines, $SM_A$, to each process and a Remote Attestation process, $P_{RA}$ to the protocol.
	\end{enumerate}

	\begin{figure}[ht!]
		\center
		\includegraphics[scale=0.39]{figures/state-machines/distributed-protocol-model-transformation0.pdf}
	\end{figure}
	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.39]{figures/state-machines/distributed-protocol-model-transformation1.pdf}
	\end{figure}
	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.39]{figures/state-machines/distributed-protocol-model-transformation2.pdf}
	\end{figure}
	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.39]{figures/state-machines/distributed-protocol-model-transformation3.pdf}
	\end{figure}
	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.39]{figures/state-machines/distributed-protocol-model-transformation4.pdf}
		\caption{Transformation of figure \ref{fig:simple-model} from crash-resistant protocol to byzantine fault-tolerant protocol.\label{fig:tranformation-model}}
	\end{figure}
	\FloatBarrier

	The transformation of the state machines consists of the following:
	\begin{enumerate}
		\item Before a process runs the protocol, a pre-compute step must be added where each process' $SM_s$ is provisioned with the same cryptographic secret. 
		This is handled by the $SM_s$ and $SM_A$, which will contact $P_{RA}$ and be Attested and securely provisioned. 
		In our example, we have only added a single $P_{RA}$, which of course means that a \textit{k}-resilient protocol suddenly cannot handle a single $P_{RA}$ crash. 
		This can be solved by adding \textit{k+1} identical $P_{RA}$s, as this is a pre-compute step. 
		This means that the $P_{RA}$s plays no further role after this step in the protocol, and can crash without effecting the running processes.
		\item All messages that were to be sent in the original protocol, must be sent from a state machine in the integrity protected area though a state machine in the unprotected area of the process.
		This is due to the constraint that the state machines in the integrity protected area of the process can no longer have channels to other processes.  
		\item Before any message intended for another process is sent from the integrity protected area, it must be have a cryptographic message authentication code (MAC) appended on the message.
		The MAC is an output of the message and the Remote Attestation provisioned key.
		$SM_s$ is the only state machine with the Remote Attestation provisioned key, and thus only $SM_s$ can MAC a message correctly.
		$SM_s$ will refuse to sign any message if any state machine in the integrity protected area is not the original.
		This translates to a transformation of the state machine, such that each transition $(s_{from}, i, \{(m_o, c_o)\}, s_{to})$, where $c_o$ is a channel that was previously to another process, must be transformed to the transitions $(s_{from}, i, \{(m_o, c_{SM_s})\}, s_{wait})$ and $(s_{wait}, (m_o+MAC, c_{SM_s}), \{(m_o+MAC, c_o)\}, s_{to})$ with the intermediate state $s_{wait}$, which acts as a state in which the state machine waits for $SM_s$ to MAC the output message.
		\item Whenever a message that supposedly originates from another process is received from the unprotected area  by a state machine in the integrity protected area, the MAC of that message must be verified by $SM_s$.
		In case this verification fails, the message must be dropped discarded.
		This translates to a transformation of the state machine, such that each transition $(s_{from}, (m_i, c_i), o, s_{to})$, where $c_i$ is a channel that was previously to another process, must be transformed to the transitions $(s_{from}, (m_i+MAC, c_i), \{(m_i+MAC, c_{SM_s})\}, s_{wait})$, $(s_{wait}, ("0", c_{SM_s}), \{\}, s_{from})$ and  $(s_{wait}, ("1", c_{SM_s}), o, s_{to})$ with the intermediate state $s_{wait}$, which acts as a state in which the state machine waits for $SM_s$ to verify the MAC of the input, and the messages $"0"$ and $"1"$ represents the failure and success of this verification, respectively.
		\item In the event that $SM_s$ is asked to sign a message from a state machine that it identifies is not the original state machines in the integrity protected area, it must discard the message.
	\end{enumerate}

	Notice that this transformation is linear in the number of messages, under the assumption that the MAC, and MAC-verification sub-routines in $SM_s$ does not add any messages.
	Each input message in the transitions is transformed to exactly one new state, three new state transitions and one MAC-verification sub-routine on $SM_s$.
	Each output-set is transformed to exactly one new state, two new state transitions and $n$ MAC sub-routines on $SM_s$ where $n$ is the size of the output set.
	Under the assumption that $SM_s$ sends no additional messages during the MAC and MAC-verification sub-routines, and no failures, $m$ messages in the original state machine will become $7m$ messages after the transformation (see table \ref{tab:number-of-messages-transformed}).
	If we only count the messages sent between processes, there is no change in the number of messages sent.

	\begin{table}[ht!]
	\centering
	\makebox[\textwidth][c]{\begin{tabular}{l|l}
	\textbf{Number of messages}     & \textbf{Origin} \\ \hline
	$m$                             &  MAC-request outputs to $SM_s$                                        \\ \hline
	$m$                             &  MAC-response inputs from $SM_s$                                      \\ \hline
	$m$                             &  messages sent to the wrapper state machine on the sending process    \\ \hline
	$m$                             &  messages sent between processes                                      \\ \hline
	$m$                             &  messages sent from the wrapper state machine on the receiving process                                                                                                 \\ \hline
	$m$                             &  input MAC verification requests to $SM_s$                            \\ \hline
	$m$                             &  verification responses from $SM_s$                                   \\ \hline\hline
	$7m$                            &  total messages            
	\end{tabular}}
	\caption{Number of messages after the transformation}
	\label{tab:number-of-messages-transformed}
	\end{table}

	\FloatBarrier
	\begin{figure}[ht!] 
		\center
		\makebox[\textwidth][c]{\includegraphics[scale=0.6]{figures/state-machines/NFA-transformation.pdf}}
		\caption{Transformation of figure \ref{fig:simple-nfa} from state machine in crash-resistant protocol to integrity protected state machine in byzantine fault-tolerant protocol, if all channels are to other processes.\label{fig:nfa-transformation}}
	\end{figure}
	\FloatBarrier

	These transformations gives us the following guarantees, if a process experiences a byzantine fault.
	Recall that we model a byzantine fault as a process being exchanged with a new process, potentially with removed, added and/or corrupted state machines.
	\begin{itemize}
		\item If a process has its transformed state machine removed, the process will exhibit exactly the same behaviour as a crash (the state machine can take no further inputs, and produce no further outputs), and so it is exactly equivalent to a crash of the state machine. 
		\item If the wrapper state machines are removed, the transformed state machine can no longer send or receive messages.
		This is again equivalent to a crash, as a token can no longer be sent to or from that state machine.
		\item If the $SM_A$ is removed, it can either happen before or after the Remote Attestation process has completed.
		If it happens before, the process's $SM_S$ will never be provisioned with the Remotely Attestation secret, and no messages will be verified.
		Therefore, the transformed state will never have its outgoing messages MAC'ed nor will it have any incoming messages verified.
		As such, it will either get stuck in a state where it never gets a response from $SM_s$ of a message MAC request, or it will get stuck in a state where a specific message cannot be verified.
		If it happens after the provisioning it will have no effect, as $SM_s$ is already provisioned, and no further communication with $SM_A$ is required.
		\item If a process gets an additional state machine in the integrity protected area, it will have no consequence, as $SM_s$ will refuse MAC'ing and verification of messages from this state machine, and it cannot communicate with other state machines, unless these are corrupted.
		\item If a process gets an additional state machine outside the integrity protected area, it cannot communicate with anything inside the integrity protected area, with corrupting these (see below). 
		It can communicate with other non-protected state machines, but this is equivalent to the other state machines being corrupted (see below).
		\item If a process has a corrupted transformed state machine (in the integrity protected area), $SM_s$ will refuse to sign any messages. 
		So any messages sent from this corrupted state machine, will not be verified on correct processes, meaning that the transformed state machines receiving this message will not transition any further than the verification state.
		\item If a process has a corrupted $SM_s$, the new $SM_s$ will, by assumption, not have access to the Attestation secret. 
		Thereby, it cannot MAC or verify messages.
		Nor can it be provisioned with the key again, as this the Remote Attestation procedure ensures that $SM_s$ is the correct state machine. 
		\item If a process has a corrupted wrapper state machine, any messages from the integrity protected area can either be dropped, changed/corrupted, redirected, or duplicated. 
		A dropped message is equivalent to a dropped message on an unreliable channel, which the protocol already handles.
		A corrupted message will not be verified by a correct receiving process's $SM_s$, and the message will be discarded.
		A redirected message will be not by verified by the receiving process, as it's $id_p$ will not match the intended recipient, and the message will be discarded.
		A duplicated message is equivalent to a duplicated message on the unreliable channel, which the protocol already handles.
	\end{itemize}
		
	This concludes the argument that Intel SGX and cryptography can change correct process behaviour under byzantine faults to behaviour equivalent that under crash faults, and thereby, using the above transformation, make a crash-resistant protocol into a byzantine-fault-tolerant protocol.
	As we will apply this transformation to our solution, we will therefore, from here on in, only consider a fault model of crashing processes.

		\subsection{Example: Central Server Mutual Exclusion}
		We will now show a practical example of how the transformation in section \ref{sec:transforming-byzantine-faults} can be utilised.
		The protocol that we will transform is the central server protocol for mutual exclusion.
		The central server protocol for mutual exclusion (from here on in CSME) is a protocol which partly solves the \textit{distributed mutual exclusion} problem.
		In the distributed mutual exclusion problem, a collection of processes share one or more resources (referred to as the \textit{critical section}), and need to do read/writes on these resources. 
		To prevent race-conditions, a mutual exclusion algorithm ensures that only a single process has access to the critical section at any given time.
		More formally, in any solution to the distributed mutual exclusion problem, the following requirements must be upheld:
		\begin{description}
			\item[ME1: Safety] At most one process may execute in the critical section (CS) at a time.
			\item[ME2: Liveness] Requests to enter and exit the critical section eventually succeed.
		\end{description}
		Optionally, some distributed mutual exclusion protocols also solves the additional fairness requirement of
		\begin{description}
			\item[ME3: Happened-before ordering]  If one request to enter the CS happened-before another, then entry to the CS is granted in that order. 
		\end{description}
		CSME does not fulfil the requirements of ME3 in asynchronous systems, and thus only partly solves the distributed mutual exclusion problem.

		CSME solves ME1 and ME2 under the conditions of no process failures.
		In broad strokes, the protocol works by deploying a central server process, which will process a request for access to the critical section in the received order, send an access token to the appropriate client process, waits for an acknowledgement from the process that access to the critical section is no longer needed, and then processes the next request.
		It is trivial that the protocol does not provide liveness under process crashes:
		If the server crashes, no process can gain access tokens, and thus no requests for access will succeed.
		The same scenario is true if a process crashes while having access to the critical section, as the server will never release the token of the crashed process.
		However, safety is still guaranteed, as a process cannot access the critical section without a token.
		Under byzantine faults, neither safety nor liveness can be guaranteed. 
		For instance, the server could serve the tokens to all requests without waiting for acknowledgements from the clients.

		We will now show how the transformation from section \ref{sec:transforming-byzantine-faults}, can transform CSME to give the same guarantees in a byzantine system as the untransformed protocol gives in a crash-fault system.
		Notice that there is no formal definition of how the critical section access and token is implemented in CSME | it can be implemented with cryptography, as partial states, with append-only memory, as another process, etc.
		We will keep this abstraction in the following transformation, but the implementation of this is also required to undergo the same transformation.
		We will omit the handling of unreliable channels on the state machines for readability, but assume that it is handled.

		First we need to model the protocol as finite state machines, channels and processes.
		We model two different state machines: a client state machine, and a server state machine.

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-client-NFA.pdf}
			\caption{Client state machine from the central server protocol for mutual exclusion. Note that the channel $c_s$ represents the unreliable channel to the server, and is different across client instances.\label{fig:CSME-client-NFA}}
		\end{figure}
		\FloatBarrier

		The client state machine is modelled in Figure \ref{fig:CSME-client-NFA}.
		It can either not have requested access to the critical section ($s_0$), wait for the token from the server ($s_1$), or have the token and be in the critical section ($s_2$). 
		Naturally it can also crash ($s_{error}$).

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-server-NFA.pdf}
			\caption{Server state machine from the central server protocol for mutual exclusion. Note that this server state machine can only handle two client processes.\label{fig:CSME-server-NFA}}
		\end{figure}
		\FloatBarrier

		The server state machine is a bit more complex as it must be modelled to account for the number of client processes.
		Figure \ref{fig:CSME-server-NFA} is a model of the server state machine in a protocol with two client processes.
		It encompasses 6 states: $s_0$ where no client has access to the critical section, and no requests has been , $s_1$ where client $1$ has requested the token and the token has been sent, $s_2$ where client $2$ has requested the token and the token has been sent, $s_3$ where client $1$ has the token and client $2$ has requested the token, $s_4$ where client $2$ has the token and client $1$ has requested the token and $s_{error}$ where the state machine has crashed.

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-protocol.pdf}
			\caption{Processes and channels in the central server protocol for mutual exclusion, with one server and two clients.\label{fig:CSME-protocol}}
		\end{figure}
		\FloatBarrier

		Figure \ref{fig:CSME-protocol} shows the processes and channels in CSME with two client processes.
		$P_1$ and $P_2$ are the clients, each running an instance of the state machine from figure \ref{fig:CSME-client-NFA}, with an unreliable channel to the server process $P_0$, which runs an instance of the state machine from figure \ref{fig:CSME-server-NFA}.

		We start the transformation by transforming the state machines to have their messages MAC'ed by $SM_s$, and to have $SM_s$ verify the messages they receive.
		This is done by rules for state machine transformation in section \ref{sec:transforming-byzantine-faults}. 

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-client-NFA-transformed.pdf}
			\caption{Client state machine in CSME, after it has been transformed to handle byzantine faults.\label{fig:CSME-client-NFA-transformed}}
		\end{figure}
		\FloatBarrier

		Figure \ref{fig:CSME-client-NFA-transformed} shows the client state machine after the transformation.
		Whenever the client wants to enter the critical section, the state machine sends the request to $SM_s$ for MAC'ing.
		When the MAC'ed message is received from $SM_s$, this message is sent to the server process. 
		The state machine is now in $s_1$, which is equivalent to $s_1$ in the untransformed state machine (figure \ref{fig:CSME-client-NFA}).
		$c_s$ is now a channel from the wrapper state machine.
		When a token is received from $c_s$, the message's MAC is sent to $SM_s$ for verification.
		If the MAC is correct, the state machine will transition to $s_2$, which is in the critical section, and is equivalent to $s_2$ in the untransformed state machine.
		Before exiting the critical section, the exit message is sent to $SM_s$ for MAC'ing, and when the appropriate MAC is received from $SM_s$, the exit message is sent to the wrapper state machine for redirection to the server process.

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\makebox[\textwidth][c]{\includegraphics[scale=0.6]{figures/state-machines/CSME-server-NFA-transformed.pdf}}
			\caption{Server state machine in the central server protocol for mutual exclusion, after it has been transformed to handle byzantine errors. Note that $s_{error}$ has been omitted for (some) readability.\label{fig:CSME-server-NFA-transformed}}
		\end{figure}
		\FloatBarrier

		Figure \ref{fig:CSME-server-NFA-transformed} shows the transformed server state machine.
		We have omitted $s_{error}$ for readability.
		$s_0$, $s_1$, $s_2$, $s_3$ and $s_4$ are equivalent to the states by the same names in the untransformed state machine (figure \ref{fig:CSME-server-NFA}).
		In $s_0$ the token has been released, and no client has requested the token.
		In $s_1$, client $1$ has requested the token, $SM_s$ has verified the MAC of the request and MAC'ed the token which has then been sent to the servers wrapper state machine for redirection to the client $1$ process.
		If the token is released by client $1$, and this message's MAC is verified, the state machine will transition to $s_0$. 
		$s_2$ is equivalent to $s_1$, except with client $2$ instead of client $1$. 
		In $s_3$, client $1$ has the token, and client $2$ has requested the token.
		So when the server state machine receives an "exit" message verifiably from client $1$, a token is MAC'ed and sent to client $2$, so the state machine can transition to $s_2$.
		$s_4$ is equivalent to $s_3$, except with the clients reversed (client $2$ has the token, client $1$ has requested it, when client $2$ releases the token).  

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-protocol-transformed.pdf}
			\caption{Processes and channels in the central server protocol for mutual exclusion, after they have been transformed to handle byzantine errors.\label{fig:CSME-protocol-transformed}}
		\end{figure}
		\FloatBarrier

		Figure \ref{fig:CSME-protocol-transformed} show the process's transformation. 
		Each of the client processes ($P_1$ and $P_2$), is now running the transformed client state machines in the integrity protected area. The transformed client state machines have a reliable channel to a $SM_s$, and another to a wrapper state machine outside the integrity protected area, which is responsible for passing on the messages to the server process.
		Each of the processes have has an $SM_A$ responsible for passing Remote Attestation messages from the $SM_s$ to the new Remote Attestation process.
		The server process is running a transformed server state machine, connected to two wrapper state machines and an $SM_s$.
		The server $SM_s$ is also connected to a $SM_A$ for attestation.

		Having transformed the CSME protocol, the correct processes will exhibit the same behaviour when other processes suffer byzantine faults, as the correct processes do in the untransformed protocol when other processes suffer crash faults.

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-protocol-transformed-byzantine.pdf}
			\caption{Processes and channels in the transformed central server protocol for mutual exclusion, with a byzantine fault on the server process.\label{fig:CSME-protocol-transformed-byzantine}}
		\end{figure}
		\FloatBarrier

		Let's see how a byzantine fault is reduced to a crash failure in the example where the server state machines tries to serve tokens on any request, without getting acknowledgement that the token has been released by the possessing client.
		There are several ways this could be modelled, one of which is presented here:
		We model this byzantine fault as $P_0$ being exchanged with $P_{byz}$.
		$P_{byz}$ (see figure \ref{fig:CSME-protocol-transformed-byzantine}) is exactly equal to $P_0$, except that $SM_0$ has been exchanged with $SM_{byz}$ (see figure \ref{fig:CSME-server-NFA-transformed-byzantine}), which serves a token to any request by the clients.

		\FloatBarrier
		\begin{figure}[ht!] 
			\center
			\includegraphics[scale=0.6]{figures/state-machines/CSME-server-NFA-transformed-byzantine.pdf}
			\caption{The byzantine fault state machine $SM_{byz}$ on the server process.\label{fig:CSME-server-NFA-transformed-byzantine}}
		\end{figure}
		\FloatBarrier

		If this byzantine fault happens, none of the tokens are MAC'ed.
		Thereby, any correct client process (figure \ref{fig:CSME-client-NFA-transformed}) will get stuck in a loop between $s_1$ and $s_1'$, when $SM_s$ rejects the (missing) MAC of the token. 
		This is equivalent behaviour to the server process crashing, as a (correct) token will never be provided, and the client is unable to enter the critical section.

	\section{Analysis}
	\label{sec:analysis}
	Recall the problem:
	We have $n$ peers $\{p_1, p_2 \dots p_n\}$, and a DCR graph $G$, which consists of $v$ events $E = \{e_1, e_2, \dots, e_v\}$.
	Each peer is responsible for $1$ or more events, where the peers responsible for $e$ stores the current and previous states of $e$. 
	Responsibility for $e$ entails involvement in executions of $e$ and executions of other events $e'$ s.t. $e \in E_{eff}(G,e')$, as the state of $e$ must be agreed upon by all responsible peers.
	A client can contact any peer responsible for $e$, requesting an execution of $e$, provided that the client has the correct credentials with regards to access control.
	Furthermore the system must have the following properties:
	\begin{description}
		\item[Safety] all peers responsible for $e$ execute the requests on $e$ in the same order.
		\item[Liveness] The client of a request eventually receives a reply to that request.
		\item[DCR linearisability] At any time before and after event executions, the states of $e_1, e_2, \dots, e_v$ must be the result of at least one run $R_G$ of $G$, such that $R_G$ contains only all successful execution requests.
	\end{description}

	% To achieve a solution to this problem there are several 

	% The problem can be solved by solving two somewhat independent sub-problems: state-machine replication (SMR) and distributed DCR graph execution.
	% We need to solve consensus on a request log to ensure safety and liveness, and we need to solve distributed DCR graph execution to solve DCR linearisability and dependence synchronisation.
	% To some extend, some SMR solutions also solve distributed DCR execution, in that they synchronise all requests from clients.
	% As mentioned in section \ref{subsec:consensus} a solution to SMR is consensus on a log, and consensus and SMR are equivalent problems.

	% There exist several solutions to both consensus and SMR, for instance \cite{bracha_asynchronous_1985,lamport_part-time_1998,castro_practical_1999,kotla_zyzzyva_2007,kapitza_cheapbft_2012,veronese_efficient_2013,ongaro_search_2014,liu_scalable_2016}. 
	% With regards to distributed DCR execution, there are only a few solutions: \cite{hildebrandt_safe_2011,hildebrandt_declarative_2012}. 


	% For the moment, we will just use an abstract solution to SMR with 2f+1 crash fault tolerance for liveness.



	% The first issue thereby presents itself, in that simultaneous client requests can lead to execution of dynamically dependent events.
	% Since the executed events are dependent, the order in which the executions are attempted is not inconsequential, as they can be mutually exclusive, or dependent on one another, such that one can be executed followed by the other, but not vice versa.
	% To solve this, the involved parties must agree on which order these executions are applied, to avoid inconsistencies in the state of the events.

	% Synchronizing state changes is a well-known problem and one solution is the election of a leader which orders the messages, such as in most BFT algorithms~\cite{castro_practical_1999,kapitza_cheapbft_2012,veronese_efficient_2013,liu_scalable_2016}.
	% %A single-leader system does however neccesitate that each peer in the system manages the entire subject state | in the case of this project the entirety of the DCR graph.
	\begin{landscape}
		\begin{table}
		\centering
		\makebox[\textwidth][c]{\begin{tabular}{ p{4cm} p{1.5cm} p{1.5cm} p{1.5cm} p{1.5cm} p{2cm} p{2.3cm} p{2cm} }
		\toprule
		\textbf{Approach}		  					& \textbf{FT: Availability}    & \textbf{FT: Safety} & \textbf{FT: Data integrity} & \textbf{Crash recovery} & \textbf{Minimum complexity for executing $e$} & \textbf{Concurrency}                 & \textbf{Request Bottleneck}    \\ 
	    \midrule
		Central Server 			  					& $0$                                        & $n$                      & $0$                         & n/a                       & $2$                                       		& $\leq$ Dynamic independence & $1$ \\
		State Machine Replication 					& $\lfloor \frac{(n-1)}{2} \rfloor$          & $n$                      & $n-1$                       & $O(n)$                    & $2\cdot\lfloor\frac{(n-1)}{2}\rfloor$     		& $\leq$ Dynamic independence & $1$ \\
		Partial state with 1 leader 				& $\lfloor \frac{(m-1)}{2} \rfloor^*$ & $n$                      & $m-1$                       & $O(n^2)$                  & $2\cdot\lfloor\frac{(m-1)}{2}\rfloor$     		& Dynamic independence & $1$ \\
		Complete distribution 					  	& $0^*$                               & $n$                      & $0$                         & n/a                       & $2\cdot D_{dyn}(G,e)$           				& Dynamic independence & $n$ \\
		Event state clusters with no common leader 	& $\lfloor \frac{(m-1)}{2} \rfloor^*$ & $n$                      & $m-1$                       & $O(m)$                    & $2\cdot\lfloor\frac{(m-1)}{2}\rfloor$     		& Dynamic independence & $\frac{n}{m}$ \\
		\bottomrule
		\end{tabular}}

		\caption[caption]{Comparison of different approaches to solving the problem. $^*$ denotes partially. \textbf{FT: Availability} is the fault tolerance of the availability guarantee. \textbf{FT: Safety} is the fault tolerance of the safety guarantee. \textbf{FT: Data integrity} is the fault tolerance of data integrity. \textbf{Crash recovery} is the number of messages required to recover from a crashing process. \textbf{Minimum complexity for executing $e$} is the minimum number of messages needed for the execution of an event. \textbf{Concurrency} is the supported level of DCR concurrency. \textbf{Request Bottleneck} is how many processes' can handle execution requests at one time.}
		\label{tab:approcach-comparison}
		\end{table}
	\end{landscape}

	We wish to create a system in which:
	\begin{itemize}
	 	\item The state of an event is agreed upon in less that $O(n)$ messages (for any graphs where two or more events are statically independent)\footnote{Trivially, a DCR graph with a single event must require $O(n)$ messages, as each peer have responsibility for at least one event, so they must have responsibility for that event.}
	 	\item while maintaining fault tolerance,
	 	\item and enabling dynamic independence concurrency of event executions.
	 \end{itemize}  
	The following is a short summary of each approach:
	
	\paragraph{Central server approach}
	The first approach is a simple central server. 
	There is a single leader, $L$, each of the other peers replicate some subset of $E$ and can redirect requests to the leader. 
	When the leader receives a request, it is queued in the order they are received in, and applied to $G$ in that order.
	After an execution of an event $e$, each of the peers replicating $e$ or an event in $E_{eff}(G,e)$ is informed by $L$ of that execution, with a monotonic counter value that enables ordering of the events' execution.
	This ensures safety, since each of the peers will apply the executions in the same order as $L$.
	Since every request is managed by a single leader, we are automatically given DCR linearisability, since the executions can be totally ordered. 
	However, this solution does not ensure any concurrency, since $L$ needs to apply each previous execution before the next.
	If some concurrency is desired, $L$ can execute requests in parallel, while keeping track of current executions.
	When an execution request is received of an event that is dynamically dependent on one of the currently executing events, it is queued, and so is all other requests that are not in the approximate static independence set of all the currently executing and queued events.
	Furthermore, there is no fault tolerance because under a leader crash, there is no guarantee that the remaining peers can recreate the last state.

	\paragraph{SMR approach}
	The next approach tries to improve on the fault tolerance of the central server approach.
	This is a classic SMR/consensus solution with crash fault tolerance.
	There are several protocols that fits this description, for instance in~\cite{bracha_asynchronous_1985,lamport_part-time_1998,lamport_lower_2006,ongaro_search_2014}, but for the purposes of this comparison, an abstract solution that utilizes a leader, $L$, to achieve an optimal crash fault tolerance of $f = \lfloor \frac{(n-1)}{2} \rfloor$ is enough.
	
	In this approach, every peer must replicate all events, as all executions must be committed to at least $f+1$ replicas.
	This ensures that if a leader dies, a new leader can be chosen (using $O(n)$ messages), which gives us the aforementioned fault tolerance.
	However, now $L$ must synchronise all requests, to ensure that they are applied in the same order by all replicas, which translates to no DCR concurrency.
	Some SMR protocols (e.g.~\cite{castro_practical_1999}) allow for concurrent request commits, under the constraint that requests that are committed must not be applied to the underlying state machine before any uncommitted request that happened-before~\cite{lamport_time_1978} on $L$.
	This constraint could be relaxed to allow for applying the execution of $e$ when the request has committed, if the peer is aware of which events is in the previous uncommitted execution requests, and none of these events are in $D_{dyn}(e)$.
	Because the peer needs to know the previous uncommitted requests, this results in worse concurrency than dynamic independence.
	Furthermore, the solution still needs $O(n)$ messages to execute a single event, no matter how the graph is constructed.

	\paragraph{Partial state, single leader approach}
	The next approach is an attempt to reduce the amount of messages needed for executing an event.
	The basic idea is to distribute the event responsibility out to a subset of peers, which will then only be responsible for that event.
	We name these subsets \textit{clusters} and denote the size of these clusters $m$. 
	The system still utilizes a single leader, which synchronises the requests.
	When event $e$ is requested executed, the leader runs an SMR algorithm similar to the one described in the SMR approach, but only with the cluster for $e$, and the clusters of $E_{eff}(G,e)$ -- to ensure that the clusters of $E_{eff}(G,e)$ has updated the state/enabledness of the events they are responsible for.
	This ensures a lesser message complexity than SMR approach, given $n > m * (|E_{eff}(G,e)|+1)$.
	Notice that $\forall e. n = m \cdot v \geq m * (|E_{eff}(G,e)|+1)$).
	Another improvement is the fact that if more than half of a cluster crashes, only part of the availability is affected, since the statically independent clusters can continue operating normally.
	However, $L$ must still synchronise all requests, and worse, cannot allow for concurrent request commits, since the peers would not necessarily be able to recreate the synchronisation between these.
	The one exception is dynamically independent events, since the order of these does not matter.
	Under leader crashes, all clusters need to synchronise their logs, which requires $O(n^2)$ messages.
	There is an argument that one could simply reduce $n$ in the SMR approach to achieve the exact same message complexity.
	While this is true for a system where we control the number of peers, it does not hold in system where the number of initial peers are constant (e.g. a system where all participants in a large DCR graph requires to be in control of some constant amount of peers), or systems where the peers independently join the network (in which case we do not control the number of peers).

	\paragraph{Complete distribution approach}
	The next approach is heavily inspired by~\cite{hildebrandt_safe_2011}.
	In it $n = v$, and each peer has responsibility for only a single event.
	There is no leader, and an execution is done through synchronisation between peers.
	I.e. if event $e$ is to be executed, the responsible peer will use a synchronisation technique (e.g. 2 phase locking) with all the peers responsible for the events in $E_{eff}(G,e)$, who will update their state accordingly.
	This guarantees DCR linearisability. 
	The fault tolerance of this approach is quite bad, as any peer crashing will result in a data loss, and effect availability, even though it has the same property as the partial state, single leader approach of not effecting the events in $I_{stat}\{e\}$

	\paragraph{Partial state, multi-leader approach}
	The last is our chosen approach, and we will go into detail with it from section \ref{subsec:algorithm}.
	It is build upon the partial state, single leader approach, except that the common leader is replaced with inter-cluster synchronisation using locks.
	This has the benefit that even if a leader dies, the recovery has message complexity $O(m)$ (instead of $O(n^2)$ in the partial state, single leader approach and $O(n)$ in the SMR approach), and the number of concurrent client requests are not bounded by the processing speed of a single process.
	From here on in, we will primarily concern ourselves with the details of the partial state, multi-leader approach.

	Table~\ref{tab:approcach-comparison} shows the guarantees of the different approaches to solving the problem.

	\subsection{Algorithm}
	\label{subsec:algorithm}
	To avoid the high number of messages associated with a fully replicated system and the message bottleneck associated with a single-leader system, we propose a multi-leader, partial state system.
	Each event is represented by a leader, who can initiate execution of that event at any given time.
	Since events can affect each other and this system is in an asynchronous setting where messages can be delayed arbitrarily, having multiple leaders can potentially lead to situations where leaders disagree on which order events have been executed in, possibly resulting in disagreement on the state of the workflow.
	The issue of synchronizing the ordering of simultaneous and incompatible executions, across multiple leaders is solved with the locking of events.  
	As locking is expensive both in regards to concurrency and the number of messages required, a minimal number of locks is desired.
	Evaluating the need for locking is concerned with how far changes from an event execution can propagate, necessitating locking, and whether or not there are identifiable cases where locks can be spared.
	A method of discerning which events need to be locked and when is described in subsection \ref{subsec:event-locking}.

	Given a method of ordering event executions, ensuring that the system can sustain faults means that each event needs to not only be stored by a leader, but rather a number of peers, called a \textit{cluster}, one of which is the leader at any given time.
	Clusters being responsible for events rather than single peers means that executions and locks need to be synchronized for each individual cluster.
	Due to the fact that these clusters can be seen as completely individual networks of peers, any consensus algorithm can be used to solve the problem of synchronizing executions and locks as it is completely detached from the locking mechanism and reduces to the problem of consensus.
	Choosing a consensus algorithm to manage the clusters is however still an important decision, as the wrong choice could form significant bottlenecks in the system.
	For this implementation we have chosen Raft \cite{ongaro_search_2014}, as the basis for the cluster consensus algorithm, with the addition of Intel SGX to reduce byzantine faults to crash-stop failures and an additional requirement with regards to leader election, to avoid deliberate crashes live-locking the network.
	The reason for choosing Raft is that it is widely used commercially, relatively simple and able to achieve consensus in very few messages.
	Additionally Raft only handles crash faults and is therefore an ideal candidate for the transformation of byzantine faults to crashes, as described earlier in section \ref{sec:transforming-byzantine-faults}.
	The consensus algorithm applied in the clusters is described in subsection \ref{subsec:cluster-consensus}.

	With the two parts described above, the graph can now progress, in the sense that events can be executed safely, but since each peer only knows the state of events which clusters it belongs to, what has transpired in the graph is implicitly distributed.
	Since the algorithm does at this point guarantee that any event can only execute, when the semantics of the graph permits it, collecting the global state is only interesting from a documentation perspective.
	Suppose that a node which is only a member of clusters of events which are never executed, that node will have no way of knowing if anything in the graph is being executed at all.
	Additionally, it is useful to know the entire state of the graph, when evaluating whether or not the graph has served its purpose.
	For these reasons, we present a simple method of collecting the global state of a DCR graph in subsection \ref{subsec:global-history-collection}.


	\subsection{Event Locking}
	\label{subsec:event-locking}

	As discussed in section \ref{sec:analysis}, the execution of non-independent events must be synchronised.
	This is achieved through locking of individual events.
	%
	%A lock on an event is defined as...
	%.... we say that event A locks event B

	For this section, we apply terms used in directed graphs and define variations of neighbourhoods with regards to DCR graphs as:
	\begin{description}
		\item[Out-neighbourhood] denoted $N_{out}(v)$, defined as the set of events where event $v'$ is in $N_{out}(v)$ iff there is a relation in $G$ that originates from $v$ and targets $v'$.
		\item[In-neighbourhood] denoted $N_{in}(v)$, defined as the set of events where event $v'$ is in $N_{in}(v)$ iff there is a relation in $G$ that originates from $v'$ and targets $v$.
	\end{description}
		
	In order to ensure that dynamically dependent events, as described in section \ref{subsubsec:concurrency}, cannot be executed simultaneously, locking is applied as a way of synchronizing attempts to execute.
	In a graph, $G(E,V)$, we define the set of locked events, $L$, on the execution of an event, $v$, as $L(v)$.
	As the way DCR propagates changes from an execution by relations and one execution cannot set any other event to executed, the locking semantics must adhere to the rules of the relations.
	Due to the semantics of DCR graphs, there is an advantage which can be leveraged with regards to when locking is needed.
	Consider a graph consisting of two events with a condition between them: $\ev{A} \crel \ev{B}$
	Events \texttt{A} and \texttt{B} are dynamically dependent, as executing first \texttt{A} and then \texttt{B} results in a different graph than executing first \texttt{B} and then \texttt{A}, since \texttt{B} cannot be executed in the latter case.
	According to the goal of preventing dynamically dependent events from executing simultaneously, when event \texttt{A} is executing, event \texttt{B} must therefore be locked.
	This is unnecessary as it is impossible for event \texttt{B} to execute before event \texttt{A} has been either executed or excluded.
	Both of the constraints share this property and since constraints furthermore do not modify states, there is no need for \texttt{A} to lock \texttt{B} or indeed for any event to lock events which it is targeting only with a constraint.

	\begin{figure}[ht!]
		\center
		\includegraphics[scale=0.5]{figures/dcr-graphs/race-condition.pdf}
		\caption{Graph illustrating the need for locking effects in $N_{out}(v)$.}
		\label{fig:race-condition}
	\end{figure}

	If \texttt{A} has effects originating from it, the need for synchronization arises as shown in Figure \ref{fig:race-condition}.
	In the graph events \texttt{A} and \texttt{B} both modify the same event state attributes and a race condition is present as a result.
	In order to prevent the race condition from having adverse effect, synchronization is needed between the two executing events, \texttt{A} and \texttt{B}.
	This means that events with effects targeting events within $N_{out}(v)$, where $v$ is the event being executed, need to lock the targeted events.

	Since effects can modify events which in turn have constraints originating from it, there are situations where locking in the neighbourhood of the executed event is no longer sufficient.

	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.5]{figures/dcr-graphs/second-degree-effect.pdf}
		\caption{Graph illustrating the need for locking in either some subset of $N_{out}(N_{out}(v))$ or some subset of $N_{in}(v) \cup N_{out}(v)$.}
		\label{fig:second-degree-effect}
	\end{figure}

	In the graph shown in Figure \ref{fig:second-degree-effect} it is shown that the locking set has to include either a subset of $N_{out}(N_{out}(v))$ or a subset $N_{in}(v) \cup N_{out}(v)$, in order to prevent the graph from ending in a state where both \texttt{A} and \texttt{B} have been executed, which should be impossible due to the execution of either including a condition on the other. %what about N_in(N_in(v))?
	In this case, the two locking methods have the same results and as no strong argument for one over the other can be formed from this basis, the simplest method is chosen, namely the locking that includes a subset of $N_{out}(N_{out}(v))$.

	According to the semantics of DCR relations (see section \ref{subsec:dcr}), the enabledness of an event, $v$, can only be changed by state changes in $N_{in}(v)$, and the state of the event can only be affected by an execution in $N_{in}(v)$. 
	Consider an event $v$.
	Executing $v$ can then change the state and enabledness of any event in $N_{out}(v)$. 
	Changes of the enabledness of an event in $N_{out}(v)$ cannot propagate\footnote{Unless the enabledness change of the event is a result of a state change of the event, e.g. if the event is excluded}, since no relation relies on the enabledness of the originating event.
	Changes of the state of an event in $N_{out}(v)$, \textit{can} propagate, since the constraining relations relies on the state of the originating event.
	But since only the constraining relations rely on the state of the originating event, the state change can only propagate enabledness changes, which in turn cannot propagate.
	Summarized we have the following cases where locking must occur:
	\begin{description}
		\item[Effect] Consider a graph of two events: \ev{A} and \ev{B}, with an effect originating from \texttt{A}, targeting \texttt{B}. 
		If \texttt{A} is executed, \texttt{B} must first be locked.
		\item[Effect-Condition] Consider a graph of three events: \ev{A}, \ev{B} and \ev{C}, with an effect originating from \texttt{A}, targeting \texttt{B} and a constraint originating from \texttt{B}, targeting \texttt{C}. 
		If \texttt{A} is executed, \texttt{B} and \texttt{C} must first be locked.
	\end{description}

	Given these two rules, all cases where locking is needed is covered.
	However, there are special cases where locking can be omitted, due to the actual effect of the an effect-relation, for example when executing an event which includes another event that is already included.

	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.5]{figures/dcr-graphs/second-degree-no-effect.pdf}
		\caption{Graph illustrating the advantage of locking in $N_{out}(N_{out}(v))$ rather than $N_{in}(v) \cup N_{out}(v)$.}
		\label{fig:second-degree-no-effect}
	\end{figure}

	In the graph shown in Figure \ref{fig:second-degree-no-effect} an execution of \texttt{A} no longer has an effect on the enabledness of \texttt{B}, as \texttt{C} has the same state before and after the execution of \texttt{A}.
	An argument can be made here for the $N_{out}(N_{out}(v))$ locking scheme over $N_{in}(v) \cup N_{out}(v)$, as it allows for optimizations in that \texttt{B} strictly does not need to be locked.
	This optimization is only possible when the state of \texttt{C} is known and since locking is only performed forwards, there is no implicit way to propagate executions backwards, meaning that \texttt{A} would not be notified of the state of \texttt{C} through executions. %Isn't locking only performed forwards because of the $N_{out}(N_{out}(v))$ locking scheme?
	The solution of simply notifying \texttt{A} of \texttt{C}'s state when changed, is insufficient as the notification might not arrive before \texttt{A} performs locking based on a previous state.
	Fixing the notifications would require locking which would thereby invalidate the attempt to reduce locking by propagating state changes.
	This means that \texttt{A} does not know the state of \texttt{C} on execution and would have to send a locking message to \texttt{C}, telling it to lock \texttt{B} if necessary.
	However, locking in two stages has the disadvantage of potentially taking twice as long, assuming that transporting a message between \texttt{A} and \texttt{C} takes the same amount of time as between \texttt{A} and \texttt{B}.
	An additional consideration, incidentally with the same trade-offs, is locking each individual event in lexicographical order, thereby minimizing the number of locks which have to be aborted, if leader collision occurs.
	Both of these solutions aim to maximize concurrency, but at the cost of messages and round-trips, which in practice could be very time consuming.

	It should be noted that the semantics of locking described here is not maximally concurrent in relation to DCR semantics.
	This is evident from the definition of dynamic independence, which describes what events should be allowed to execute concurrently.
	We illustrate this in the three following cases:
	\begin{itemize}
		\item Consider a graph $\ev{A} \erel \ev{B}, \ev{C} \erel \ev{B}$. When \texttt{A} is executing, it locks \texttt{B}. If \texttt{C} then attempts to execute it will need a lock on \texttt{B} as well. \texttt{B} could choose to accept both of these locks, as they have exactly the same effect on the graph.
		\item Consider a graph $\ev{A} \irel \ev{B}, \ev{C} \erel \ev{B}$. When \texttt{A} is executing, it locks \texttt{B}. If \texttt{C} attempts to execute, it is clear that it should not be allowed to obtain a lock until \texttt{A} finishes executing. However, even though \texttt{B} is locked by \texttt{A}, \texttt{B} should be allowed to execute, as it is dynamically independent with \texttt{A}.
		\item Consider a graph $\ev{A} \irel \ev[100]{B}, \ev[100]{B} \crel \ev{C}$. When \texttt{A} is executing, it will lock \texttt{B} and \texttt{C} due to the constraint originating from \texttt{B} and targeting \texttt{C}. This is not needed, as the condition relation is invalidated by the fact that \texttt{B} is executed. 
	\end{itemize}

	For the implementation described in this thesis, the simpler rules of locking is implemented, namely always locking on \textbf{Effects} and on \textbf{Effect-Conditions} as described earlier.

	\subsection{Cluster Consensus}
	\label{subsec:cluster-consensus}

	\begin{table}[ht!]
	\centering
	\makebox[\textwidth][c]{\begin{tabular}{l p{1.7cm} p{1.5cm} l p{1.7cm}}
    \toprule
	\textbf{Algorithm} 								& \textbf{Fault tolerance (liveness)} & \textbf{Crash recovery} & \textbf{Messages/execution}  & \textbf{Fault type tolerance} \\
    \midrule
	PBFT~\cite{castro_practical_1999}               & $\lfloor \frac{n-1}{3} \rfloor = f$ & $(2f+1)^2$              & $(2f+1)+(2f+1)^2$            & Byzantine 				     \\
	MinBFT~\cite{veronese_efficient_2013}           & $\lfloor \frac{n-1}{2} \rfloor = f$ & $(f+1)^2$               & $2(f+1)+(f+1)^2$             & Byzantine 				     \\
	FastBFT~\cite{liu_scalable_2016}           		& $\lfloor \frac{n-1}{2} \rfloor = f$ & $(f+1)^2$               & $4(f+1)$                     & Byzantine 				     \\
	Chandra-Toueg~\cite{chandra_unreliable_1996}    & $\lfloor \frac{n-1}{2} \rfloor = f$ & $0$                     & $4(f+1)+(f+1)^2$             & Crash                         \\
	Paxos~\cite{lamport_part-time_1998}  			& $\lfloor \frac{n-1}{2} \rfloor = f$ & $0$                     & $4(f+1) + 2$                 & Crash                         \\
	Raft~\cite{ongaro_search_2014}               	& $\lfloor \frac{n-1}{2} \rfloor = f$ & $2(f+1)$                & $2(f+1)$                     & Crash                         \\
    \bottomrule
	\end{tabular}}
	\caption{Comparison of different consensus algorithms}
	\label{tab:comparison-consensus-algorithms}
	\end{table}
	Each cluster requires a SMR/consensus algorithm to achieve consensus on the state of their shared event.
	Table~\ref{tab:comparison-consensus-algorithms} shows a comparison between some classical SMR/consensus algorithms.
	Notice that each of the crash tolerant algorithms can be made into byzantine resistant algorithms using the transformation from section~\ref{sec:transforming-byzantine-faults}\footnote{MinBFT and FastBFT already uses TEE elements, which is why they can offer better fault tolerance than $3f+1$ under byzantine errors.}.
	We have chosen to use the \textit{Raft} algorithm from~\cite{ongaro_search_2014}, due to its relative simple implementation, and low message requirements for execution and crash recovery\footnote{Raft gives the same guarantees as \textit{Multi Paxos}~\cite{lamport_part-time_1998}, but due to the separation of leader elections and request commits, it has worse crash recovery and better commit message complexity.}.
	Basic Raft is vulnerable to DDoS attack if two peers cannot receive messages from each other.
	We have therefore extended the basic algorithm slightly, to protect against this vulnerability.
	We have done so, since we assume byzantine errors on the SGX-transformed algorithm, which means that the byzantine errors can effect the channel-wrappers on each peers, and cause coordinated message omission.

	\subsection{Global history collection} % CheapShot
	\label{subsec:global-history-collection}

	Since changes in the workflow are not synchronized across every peer, the global history of the workflow at any given time is not readily available.
	We define a global history to be a DCR run, i.e. it is a sequence of event executions.
	Both as documentation of the process at deprecation of the workflow and during the life cycle of the workflow, the global history is relevant, in the latter case because the global state can be derived from the global history.
	In this section we will refer to each cluster as the event itself, for simplicity.
		
	For a global history to be collectible, each event need to track more than just their own executions.
	Events must also track all executions that changes the state and enabledness of the former.
	As locked events are implicitly notified of an execution upon unlocking, tracking these are trivial.
	There are, however, cases where locking is not performed, as locking is mostly concerned with preventing race conditions, but where enabledness is affected, such as the case of: $\ev{A} \crel \ev{B}$, where \texttt{B} can not execute before \texttt{A} is executed or excluded.
	In addition to locking, events in which enabledness is affected by an execution must therefore also be informed about that execution, so that they are able to execute.

	It is assumed that informing events is attempted until the informed event responds.
	Under this assumption, an arbitrary amount of time can pass before an event is actually notified, but as this does not allow executions to happen which violate the semantics of DCR; it is reduced to a question of fairness, which will not be discussed in this thesis\footnote{Fairness in the sense that two events which enabledness is affected by an execution will not necessarily be notified of that execution at the same time, thereby allowing one event to execute before the other.}.

	The standard for representing the state of a continuous system in an asynchronous setting is by finding a consistent cut \cite{lamport_time_1978}, which is defined by the happened-before relations:
	
	\begin{description}
		\item[Happened-before 1 (HB1)] Process events occurring on the same process can be ordered in happened-before relations.
		\item[Happened-before 2 (HB2)] There is a happened-before relation between the sending and the reception of a message.
		\item[Happened-before 3 (HB3)] Happened-before relations are transitive. 
	\end{description}

	A consistent cut means that all events obey the happened-before rules within the cut, meaning:
	\begin{itemize}
		\item If an event, \textit{a}, happened before another event, \textit{b}, and \textit{b} is included in the cut, then so is \textit{a}.
		\item If a message is received within the cut, the sending of that message must also be within the cut.
	\end{itemize}

	One way to achieve a consistent cut, is to implement Chandra and Lamport's Snapshot algorithm~\cite{chandy_distributed_1985}.
	This would require incorporation of the snapshot algorithm into the raft algorithm, increasing the complexity even more.
	Instead, we present an alternative solution, where the client requesting the global history requests the execution log from each event cluster.
	The algorithm we present for collecting the global history, does so without locking or pausing the network.	
	There is, however, considerations in that each event will then have their individual perceived sequence of executions, which might be dissimilar due to arbitrary message delays.
	After receiving an answer from each cluster, the client is able to merge the local executions sequences into a consistent cut, using the following algorithm. 

	Given a cut from a graph, it is always possible to reduce the cut until consistency is at some point attained.
	Transactions, in terms of execution sequences, is represented in executions of an event stored returned in the sequence of that event, sent messages, and in events notified of that execution, received messages.
	Therefore if any event returns an execution of another event and that execution is not present in the sequence returned by the latter event, it must be disregarded from the cut as it violates HB2.
	Since this could lead to violation of HB1, each execution recorded after the disregarded execution is also disregarded.

	Consider a simple graph of two events with a condition between them: $\ev{A} \crel \ev{B}$.
	A global history collection is started, by a client requesting it from every cluster, and \texttt{A} is the first to send its execution sequence $\{\}$, after which it executes, followed by an execution of \texttt{B}.
	\texttt{B} then receives the message asking for state and responds with a sequence of $\{\texttt{A}, \texttt{B}\}$.
	In this specific example it is not immediately apparent it could be problematic to assume that \texttt{B} is correct and therefore accept its sequence as the global history.
	However, if \texttt{A} is not able to be executed immediately, it is impossible to interpolate what has happened.
	An example of this is the graph $\ev{A} \erel \ev{B} \crel \ev{C} \crel \ev{D}$, where the collection of the global history could return an empty sequence for \texttt{A}, \texttt{B} and \texttt{C}, but a sequence of $\{\texttt{C}, \texttt{D}\}$ from \texttt{D}.
	It is unknown whether an execution of \text{A} or an execution of \texttt{B} allowed the execution of \texttt{C} and then \texttt{D}.
	To solve this, any execution not present in the sequence returned by the event itself is considered invalid and therefore that execution is deleted from the sequence of all events, as well as all following executions in that sequence.
	In the above example, this would mean that the execution of \texttt{B} in the history of \texttt{C} would be deleted, along with the execution of \texttt{C} as it follows the execution of \texttt{B}.
	The reason for this procedure is that if these executions are not omitted, a consistent cut is no longer guaranteed.

	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.6]{figures/dcr-graphs/global-history-collection-consistent-cut.pdf}
		\caption{Global history collection consistent cut. Note that each message represents the entire execution process. The green and blue executions illustrate two possibilities which could have preceded \texttt{D}'s perceived execution sequence of $\{\texttt{C}, \texttt{D}\}$. The red, dotted line shows an inconsistent cut and the black, dotted line shows the consistent cut.}
		\label{fig:global-history-collection-consistent-cut}
	\end{figure}

	In Figure \ref{fig:global-history-collection-consistent-cut} the example from above is shown.
	As a consistent cut requires that any message received within the cut must also be sent within the cut, it is clear that the cut described in the figure is inconsistent.
	The method of fixing an inconsistent cut described earlier, is the equivalent of ignoring that \texttt{D}'s cluster has received an execution message from \texttt{C}, which also renders the execution of \texttt{D} invalid.
	Cuts made in a DCR graph adhering to the tracking rules outlined here, and the implicit tracking of locks, will always be locally consistent up to a point, meaning that they are guaranteed to uphold the first premise of happened-before relations (HB1), namely ordering of local process events.
	Given that these events will always present a local sequence adhering to HB1, there must be some point for each process which is consistent with another point in each other process.
	Each event will always be able to present an empty sequence, as an example of a consistent cut.
	Since all messages received within the cut are discarded along with all later executions if the message is not sent within the same cut, it follows that it is eventually possible to obtain a consistent cut, as worst case an empty sequence of executions would be applicable.

	Note that dynamically independent activities can cause sequences apparently contradicting one another.
	For example, a graph of $\ev{A} \crel \ev{B}, \ev{A} \crel \ev{C}, \ev{D} \crel \ev{B}, \ev{D} \crel \ev{C}$ could by executing \texttt{A} and \texttt{D} cause events \texttt{B} and \texttt{C} to perceive execution sequences of $\{\texttt{A}, \texttt{D}\}$ and $\{\texttt{D}, \texttt{A}\}$ respectively.
	This would appear to violate HB1, but since an event is notified of another events execution without locking, it should be seen as sent and received messages.
	When \texttt{A} executes, it sends a notification to \texttt{C} and notes it in its execution sequence.
	When \texttt{C} receives a notification it notes it in its execution sequence.
	Thereby HB1 is not violated, as the execution of \texttt{A} is represented by two different events, meaning that it is covered by HB2.

	Now that a consistent cut is guaranteed, a valid execution sequence then has to be interpolated.

	\begin{figure}[ht!] 
		\center
		\includegraphics[scale=0.6]{figures/dcr-graphs/global-history-collection-example.pdf}
		\caption{Example graph illustrating global history collection.}
		\label{fig:global-history-collection-example}
	\end{figure}

	From the graph shown in Figure \ref{fig:global-history-collection-example}, the shown sequences are collected for each event and form a consistent cut.
	Note that each execution of an event is uniquely identifiable, which is also the case in the algorithm described in this thesis, as it is needed by the cluster consensus part described in section \ref{subsec:cluster-consensus}.

	From each sequence, an implicit valid ordering is present, in the sense that from event \texttt{B} it is shown that execution $B_1$ can happen before $A_1$ happens.
	An aggregation of these sequences needs to be found, which can be accomplished through the construction of a directed graph and topologically sorting it.
	Before an aggregation can be performed, we define each sequence as a series of execution relations.
	For example the execution sequence recorded by \texttt{B} could also be formulated as: $A_1 \rightarrow B_1, B_1 \rightarrow E_1, E_1 \rightarrow F_1, F_1 \rightarrow E_2, E_2 \rightarrow F_2$.
	Once each execution sequence is formulated in that way, they are aggregated to make a complete list of rules that any valid execution sequence must follow.
	For the example illustrated in Figure \ref{fig:global-history-collection-example}, this results in the following list of rules: $A_1 \rightarrow B_1, A_1 \rightarrow D_1, B_1 \rightarrow E_1, E_1 \rightarrow F_1, F_1 \rightarrow E_2, E_2 \rightarrow F_2, E_1 \rightarrow E_2, E_2 \rightarrow F_1, F_1 \rightarrow F_2, F_2 \rightarrow C_1$

	\begin{figure}[ht!]
		\centering
		\begin{minipage}[b]{0.49\textwidth}
			\includegraphics[width=\textwidth]{figures/dcr-graphs/execution-sequence-graph-example1.pdf}
			\caption{Initial graph made from sequence rule aggregation.}
			\label{fig:execution-sequence-graph-example1}
		\end{minipage}
		\hfill
		\begin{minipage}[b]{0.49\textwidth}
			\includegraphics[width=\textwidth]{figures/dcr-graphs/execution-sequence-graph-example2.pdf}
			\caption{Directed acyclic graph version of graph shown in Figure \ref{fig:execution-sequence-graph-example1}.	}
			\label{fig:execution-sequence-graph-example2}
		\end{minipage}
	\end{figure}

	From the list of rules, a graph can now be constructed of possible executions, as seen in Figure \ref{fig:execution-sequence-graph-example1}.
	In order to extract an actual valid execution sequence, a topological ordering needs to be applied, but as this is only valid in acyclic graphs, cycles are collapsed into single nodes, as shown in Figure \ref{fig:execution-sequence-graph-example2}.
	This is still valid, as cycles in the happened-before relationships of executions, entails that the executions happened concurrently.
	And since the locking rules from section \ref{subsec:event-locking}, only allow concurrent executions when the events are dynamically independent, any linearisation of the concurrent executions must result in the same state of the graph. 
	After collapsing any cycles, topological ordering can then be performed resulting in a valid execution sequence, for example $A_1D_1B_1E_1E_2F_1F_2C_1$
	
	The complexity of this operation is dominated by the process of ensuring a consistent cut.
	If there are \textit{n} events, each with a sequence of length \textit{m}, there is a total of $n \cdot m$ elements.
	Each element has to be checked against the elements in the list of the executed element, \textit{m} again and since an inconsistency can lead to a new inconsistency, the worst case means this has to be iterated over $\frac{n}{2}$ times.
	This results in a complexity of $\frac{n^2}{2}\cdot m^2 = O(n^2 \cdot m^2)$.
	When the consistent cut has been found, Johnson's algorithm for finding elementary circuits~\cite{johnson_finding_1975}, %can be changed!
	can be used to find all simple cycles in $O((n+e)(c+1))$, where $n$ is the number of nodes, $e$ is the number of edges, and $c$ is the number of cycles.
	At last, the graph must be topologically ordered into a linearisation, which can be done in $O(n+e)$ using depth-first search~\cite[section 22.4]{cormen_introduction_2009}.
	All in all, the complexity of this operation is dominated by the process of ensuring a consistent cut, resulting in the complexity $O(n^2 \cdot m^2)$,which is expensive, but well within the reasonable limit of local computations.


	\subsection{Raft}
	Raft is a variation of multi-Paxos establishing consensus between processes over a continuous stream of commands.
	Like Paxos, Raft uses a leader to order commands and tolerates $f = \lfloor \frac{n - 1}{2} \rfloor$ (crash) faults.
	The implementation of the Raft algorithm differs heavily from that of multi-Paxos, but the guarantees provided are very similar.

	In Raft, a processor is either a leader, follower, or (leader) candidate.
	To circumvent FLP, Raft operates under partial synchrony \cite{dwork_consensus_1988} and only keeps a leader for a single term.
	If a processor has not heard from the leader for some time period $\Delta$, the processor will start an election to move processors to the next term and elect a new leader.
	As for any partially synchronous consensus algorithms, these elections can potentially go on forever if network latency permanently exceeds $\Delta$.
	However, in real-life systems where $\Delta$ is set above the normal network latency, this is a reasonable restriction.

	Every processor keeps an indexed log of commands and what term they were added in.
	A processor keeps track of the current term and, upon receiving any request or response with a higher term, updates its term and becomes a follower.
	A processor also keep track of the last known command it knows the leader deems to be committed.
	Log entries at or below the commit index are durable while log entries above the commit index may change following an election.

	\subsubsection*{Election}
	During an election, a follower experiencing a leader timeout will become a candidate. The candidate attempts to receive a majority vote from the remaining processors, endorsing it as leader in the following term.
	Followers will grant the vote if
	\begin{enumerate*}[label=\textbf{(\alph*)}]
	  \item the candidate's term is not below the follower's term,
	  \item the follower has not yet voted in the term,
	  \item and the candidate's log is at least as up-to-date as the follower's log.
	\end{enumerate*}
	Specifically we say that the candidate broadcasts the message $\MSG{\REQ\ELECTION, t, last_t, last_i}$, where $t$ is the term the candidate is attempting to win, while $last_t$ and $last_i$ are the term and index of last entry in the candidate's log.
	For a candidate's log to be up-to-date with a follower's log, the follower's log must neither contain an entry $l$ with $l_{(term)} > last_t$ nor $l_{(term)} = last_t$ and $l_{(index)} > last_i$.
	When a candidate receives a majority vote (including its own vote), it becomes the leader.
	Like followers timing out after time period $\Delta$ of not hearing from the leader, a candidate times out after time period $\Delta$ of not winning the election.
	This can happen when split votes occur or when the network is in a period of asynchrony.
	Candidate timeouts work exactly like follower timeouts; the candidate starts an election for the next term.
	To reduce the chance of split votes following leader crashes, in practice $\Delta$ is set to a random value between some $\Delta_{min}$ and $\Delta_{max}$ at each processor.

	\subsubsection*{Leading}
	A leader receives commands from clients, directs followers to replicate the commands in their logs, and ensures that a majority of the network agree on the order of commands in their logs.
	To accomplish this, the leader will broadcast $\MSG{\REQ\APPEND, t, prev_t, prev_i, commit_i, entries}$ messages either following client requests or as no-op heartbeats to prevent follower timeouts.
	Here $t$ is the leader's term, $prev_t$ and $prev_i$ the term and index of the last entry in the leader's log, $commit_i$ the index of the last committed log entry, and $entries$ a series of log entries followers should append after the $(prev_t, prev_i)$ entry.
	Followers will either accept or deny such a request.
	\begin{itemize}
	  \item If a majority of followers has accepted to append an entry at index $i$, and $i > commit_i$ for the leader, the leader will set $commit_i \leftarrow i$ as a majority-replication makes the entry durable even through elections.
	  The next append message will propagate the new $commit_i$ to followers.
	  This has no relation to the durability of committed entries, but simply allows followers to apply committed commands to their state machine safely.
	  \item If a follower denies a request to append, the follower is missing the $(prev_t, prev_i)$ entry in its log.
	  Following a denial, the leader will send a new append message $\MSG{\REQ\APPEND, term, prev_t', prev_i', commit_i, entries'}$, where $prev_i' = prev_i - 1$, $prev_t' = log[prev_i']_{(term)}$, and $entries' = append(entries, log[prev_i'])$.
	  Repeating this process the log entry at which the follower and leader logs diverge will eventually be reached.
	\end{itemize}

	\subsubsection*{Following}
	Finally a follower processor will receive $\MSG{\REQ\APPEND, t, prev_t, prev_i, commit_i, entries}$ requests from leaders.
	A follower will deny such a request if
	\begin{enumerate*}[label=\textbf{(\alph*)}]
	  \item the followers $term > t$ or
	  \item no entry with term $prev_t$ and index $prev_i$ exists in the follower's log.
	\end{enumerate*}
	Otherwise the request is accepted.
	As logs may have diverged between the follower and leader, the follower must remove all entries following the $(prev_t, prev_i)$ entry from its log.
	After this operation all $entries$ can be safely appended to the follower's log.
	Further, following an accepted append request, the follower can apply any log entry $l$ for which $l_{(index)} \le commit_i$. (Note that $log[commit_i]$ does not necessarily exist in the followers log yet, as commits require majority, not unanimity.)

	\subsubsection*{Properties of Raft}
	Raft guarantees the following properties when the amount of faults is $\le \lfloor \frac{n - 1}{2} \rfloor$ (the highest achievable fault tolerance for the consensus problem \cite{lamport_lower_2006}).
	\begin{figure}[h]
	  \centering
	  \begin{minipage}{0.8\textwidth}
	    \begin{framed}
	      \begin{description}
	        \item[Election Safety:]  at most one leader can be elected in a given term.
	        \item[Leader Append-Only:] a leader never overwrites or deletes entries in its log; it only appends new entries.
	        \item[Log Matching:] if two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index.
	        \item[Leader Completeness:] if a log entry is committed in a given term, then that entry will be present in the logs of the leaders for all higher-numbered  terms.
	        \item[State Machine Safety:] if a server has applied a log entry at a given index to its state machine, no other server will ever apply a different log entry for the same index.
	      \end{description}
	    \end{framed}
	  \end{minipage}
	  \caption{Guarantees given by raft. (From fig. 3 of \cite{ongaro_search_2014}.)}
	  \label{fig:raft-properties}
	\end{figure}

	\subsubsection*{Timeout liveness vulnerability}
	\begin{figure}[t]
	  \centering
	  \includegraphics[width=\textwidth]{figures/raft-liveness-vuln.pdf}
	  \caption{Denial of service attack from malicious processor $M$ against correct processors $C_1$ and $C_2$. $M$ can repeat the above to continue the attack.}
	\end{figure}

	As previously discussed, Raft in its basic structure is vulnerable to disruption of liveness even after a byzantine transformation via SGX.
	A malicious processor may exploit this weakness by
	\begin{enumerate*}[label=\textbf{(\alph*)}]
	  \item dropping all heartbeat (empty append) messages from leaders when follower and
	  \item dropping all messages to and from any processor when leader.
	\end{enumerate*}
	As a result of \textbf{(a)}, the malicious processor will timeout and start an election whenever the leader has nothing to append for time period $\Delta_{min}$ (resulting in a heartbeat instead of regular append).
	The malicious processor is likely to win this election as, as the leader has not actually crashed.
	The correct processors will only contest such an election if the leader actually crashes or the network is sufficiently delayed.
	The malicious processor must not drop non-empty append messages, as a candidate must be up to date from the viewpoint of a majority of processors.

	As a result of \textbf{(b)}, immediately after becoming leader, the malicious processor will stop communicating with the rest of the network, causing correct processors to timeout and start yet another election.
	When a new leader is elected, the process starts over from \textbf{(a)}.
	In this situation, there is a window between \textbf{(b)} and \textbf{(a)} where a correct leader can append entries before the malicious processor becomes leader again.
	Thus, liveness may not be completely lost, but the throughput of the algorithm is negatively affected.
	If two malicious processors collude to swap leadership using the above strategy, liveness will be lost until the network becomes asynchronous and possibly elects a correct processor as leader.

	To mitigate the effect of this vulnerability, \cite{ongaro_search_2014} suggest an extra message phase before a processor starts an election.
	In this pre-election phase, a timed out processor will poll the other processors on whether or not they would grant their vote in a potential election.
	The other processors will say yes if
	\begin{enumerate*}[label=\textbf{(\alph*)}]
	  \item the conditions of a normal election are fulfilled (newest term, have not voted in term, up-to-date log) and
	  \item they have not themselves received a message from the leader for time period $\Delta_{min}$.
	\end{enumerate*}
	Only after receiving a majority of pre-election endorsement, the timed out processor will increment its term and start a proper election.
	Because of \textbf{(b)} a malicious processor can not convince an SGX-transformed Raft algorithm to start an election by dropping leader messages.

	\subsubsection*{Leader liveness vulnerability}
	Another liveness vulnerability exists when a malicious processor drops selected messages.
	A malicious processor can temporarily prevent liveness by
	\begin{enumerate*}[label=\textbf{(\alph*)}]
	  \item acting correctly when not leader and
	  \item dropping all client messages when leader.
	\end{enumerate*}
	The malicious processor will eventually become leader in an asynchronous setting following \textbf{(a)} and then prevent any commands to be committed following \textbf{(b)}.
	The first solution that comes to mind allows the client to accuse the leader of being malicious, forcing the remaining processors to elect a new leader.
	However, this solution opens the network up for a denial of service attack by a malicious client.
	A second solution allows a client to broadcast a command to all processors when unable to contact the leader.
	The processors will piggyback the broadcast command on their next message to the leader, forcing the leader to either drop all messages or appending the command.
	We have chosen to implement neither of these solutions and instead disregard the problem as it cannot permanently prevent liveness.
	Given the argument that \textbf{(a)} causes the malicious processor to eventually become leader, it follows that another processor will eventually overthrow the malicious processor, restoring liveness.

	\subsection{Protocol}
	We use Raft to implement event locking (section \ref{subsec:event-locking}) and cluster consensus (section \ref{subsec:cluster-consensus}), by exploiting the guarantees given by figure \ref{fig:raft-properties}.
	We define three command types for accomplishing this:
	\begin{description}
	  \item[\normalfont$\MSG{\REQ\COMMAND, tag, e, \ENUM{LOCK}}$:] request the exclusive lock to execute event $e$.
	  \item[\normalfont$\MSG{\REQ\COMMAND, tag, e, \ENUM{ABORT}}$:] release the lock to execute event $e$ without modifying any state.
	  \item[\normalfont$\MSG{\REQ\COMMAND, tag, e, \ENUM{EXEC}}$:] execute the event $e$ and modify state accordingly.
	\end{description}
	Recall the definition of a DCR graph $G(E, R)$ comprising of event set $E$ and relation set $R$.
	Also recall the definition of the set of events to be locked when executing an event $e$ as $L(e)$ (semantically defined in section \ref{subsec:event-locking}).
	% L(e) might have two definitions in locking section
	We define the set of processors replicating event $e$ (cluster for $e$) as $C(e)$ and their leader as $C_{leader}(e)$.
	With this we define the set of cluster leader processors that must be locked when executing en event $e$ as $L_{leaders}(e) = \bigcup_{e' \in L(e)} C_{leader}(e')$.
	We say $committed(entry, leader)$ is true iff $entry$ has been added to the log of $leader$ at index $i$ and $commit_i \ge i$.

	For processors in the leader state, we extend Raft with a state machine that can intercept incoming Raft messages, send new \ENUM{COMMAND} messages, and gets notified when a log entry is committed.

	\subsubsection*{Normal Operation}
	A cluster leader $p_l$ receives $\MSG{\REQ\COMMAND, tag_{lock}, e, \ENUM{LOCK}}$ requests from clients or other cluster leaders.
	During intercept the extension checks whether the leader's log is in a lockable state: is the last log entry not a $\ENUM{LOCK}$ and, based on the log, is $e$ enabled?
	If no, respond with $\MSG{\RSP\COMMAND, tag_{lock}, false}$.
	If yes, pass the $\REQ\COMMAND$ request onto Raft.

	When a $(tag_{lock}, e, \ENUM{LOCK})$ entry is committed, a cluster leader will do one of two things:
	If $p_l \ne C_{leader}(e)$, $p_l$ is not responsible for the terminating the execution attempt.
	In this case we rely on Raft to respond to the $\REQ\COMMAND$ request to let $C_{leader}(e)$ know $p_l$'s cluster is locked for execution of $e$.
	If instead $p_l = C_{leader}(e)$, $p_l$ must continue terminating the execution attempt by locking $L(e)$.
	To do this $p_l$ sends $\MSG{\REQ\COMMAND, tag_{lock}, e, \ENUM{LOCK}}$ to processors $L_{leaders}(e)$.
	Notice the tag is reused for this secondary lock.
	Further, $p_l$ notes $lock_{count}(tag_{lock}) \leftarrow 0$.

	A cluster leader $p_l$ will intercept $\MSG{\RSP\COMMAND, tag, success}$ responses when the last log entry is $(tag_{lock}, e, \ENUM{LOCK})$ and $tag = tag_{lock}$.
	If $success = true$, $p_l$ increments $lock_{count}(tag_{lock})$.
	Otherwise a lock on the cluster of an event in $L(e)$ was denied and $p_l$ must abort the execution attempt.
	To do this $p_l$ simultaneously passes $\MSG{\REQ\COMMAND, tag_{abort}, e, \ENUM{ABORT}}$ to its Raft component and sends the request to $L_{leaders}(e)$.

	When $lock_{count}(tag_{lock}) = |L(e)|$, $e$ can safely be executed. $p_l$ sends $\MSG{\REQ\COMMAND, tag_{exec}, e, \ENUM{EXEC}}$, $m_{exec}$, to its Raft module.
	When $(tag_{exec}, e, \ENUM{EXEC})$ is committed, $p_l$ sends $m_{exec}$ to $L_{leaders}(e)$.

	\subsubsection*{Leader Recovery}
	As cluster leaders may crash at arbitrary times, we must be able to safely continue from any step of an execution attempt as a newly elected leader.
	We accomplish this mainly by exploiting the Leader Completeness property (figure \ref{fig:raft-properties}).
	After being elected, a new leader $p_l'$ will look at last log entry to determine if it needs to restart a step to finish an execution attempt of a previous leader.
	Recall that an entry, which has been committed by a leader, will not necessarily be in the committed state for the successor.
	The Leader Completeness property only ensures that it eventually will be committed at the successor.
	If the last entry is not committed at $p_l'$, no action is needed as normal operation will handle when it eventually commits.
	Similarly, if the last entry is $(tag, e, type)$ where $p_l' \ne C_{leader}(e)$, no extra action is needed from $p_l'$.
	Otherwise if $p_l' = C_{leader}(e)$, branch on the last entry as follows:
	\begin{itemize}
	  \item $(tag_{lock}, e, \ENUM{LOCK})$\\
	  Send $\MSG{\REQ\COMMAND, tag_{lock}, e, \ENUM{LOCK}}$ to $L_{leaders}(e)$. Recall that $\REQ\COMMAND$ requests with the same tag will not result in duplicate entries. If the old leader already sent some or all of these requests, $p_l'$ will simply be notified of their result.

	  \item $(tag_{abort}, e, \ENUM{ABORT})$\\
	  Send $\MSG{\REQ\COMMAND, tag_{abort}, e, \ENUM{ABORT}}$ to $L_{leaders}(e)$.

	  \item $(tag_{exec}, e, \ENUM{EXEC})$\\
	  Send $\MSG{\REQ\COMMAND, tag_{exec}, e, \ENUM{EXEC}}$ to $L_{leaders}(e)$.
	\end{itemize}
	As a final note on leader recovery, we must ensure progress at some $p_l$ when attempting to execute $e$ even though leaders of $L_{leaders}(e)$ crash.
	This requires $p_l$ to resend any $\REQ\COMMAND$ requests it does not receive a $\RSP\COMMAND$ response from for some set time period.

	\subsubsection*{Termination Argument}
	\begin{figure}[t]
  	\includegraphics[width=\textwidth]{figures/raft-2pc.pdf}
	  \caption{State machine for $C_{leader}(e)$ during execution of $e$ with states start ($\bm{S}$), intermediate locked ($\bm{L}'$), locked ($\bm{L}$), abort ($\bm{A}$), and execute ($\bm{E}$). Similar to \cite{skeen_nonblocking_1981} we show received and sent messages above and below the line subscripted with the origin or destination process. We also show appending and committing entries in $C(e)$ as messages.}
	  \label{fig:raft-2pc}
	\end{figure}

	This locking scheme is very similar to centralized two phase commit \cite{skeen_nonblocking_1981}, where a leader safely advances a set of replicas to a commit or abort state.
	As described in \cite{skeen_nonblocking_1981}, two phase commit is a blocking protocol, meaning a leader or replica processor crash will halt the system until the crashed processor recovers.
	This is still true for our application of the two phase commit protocol, but we have augmented each site with an event cluster.
	Because of this a single processor crash cannot block the two phase commit.
	Blocking of an attempt to execute $e$ can occur at the earliest when a cluster in $\bigcup_{e' \in L(e)} C(e')$ experiences crashing of a majority of processors.

	To show our proposed algorithm always terminates, when no involved cluster experiences a majority crash, we will examine the event of a cluster leader crashing during an execution attempt.
	Specifically we will examine the $C(e)$ cluster when attempting to execute some event $e$, as the argument for termination at clusters $\bigcup_{e' \in L(e)} C(e')$ will follow naturally.
	After having entered state $\bm{L}'$ of figure \ref{fig:raft-2pc}, $C_{leader}(e)$ will have begun committing a lock entry at its cluster. Because Leader Completeness only applies to committed entries, we need this extra state to ensure that a successor of $C_{leader}(e)$ will be aware of the lock.
	Was $C_{leader}(e)$ to append the lock entry locally while simultaneously commanding clusters $\bigcup_{e' \in L(e)} C(e')$ to append the lock entry, we risk that a successor of $C_{leader}(e)$ would be unaware of the lock commands by its predecessor resulting in a stuck state for $\bigcup_{e' \in L(e)} C(e')$.
	If $C_{leader}(e)$ crashes at $\bm{L}'$, the lock entry will either exist in the successor's log, and we simply continue, or it will be lost, sending the successor back to state $\bm{S}$.
	This is fine as the client requesting the execution must be ready to resend commands, when leaders crash, as per the Raft algorithm design.

	At state $L$ a crash of $C_{leader}(e)$ is safe, as Leader Completeness guarantees the lock to be known by the successor.
	By redoing the $\bm{L}' \rightarrow \bm{L}$ transition, the successor can safely reenter $\bm{L}$ as duplicate command messages are allowed by Raft.

	Notice when transitioning from $\bm{L}$ to $\bm{A}$ or $\bm{E}$, no intermediate state is needed and an entry can be appended to $C(e)$ simultaneously with sending commands to $\bigcup_{e' \in L(e)} C(e')$.
	If $C_{leader}$ crashes at $\bm{A}$ or $\bm{E}$, a successor risks moving back to $\bm{L}'$, as the $\ENUM{ABORT}$ or $\ENUM{EXEC}$ entry may be lost completely and the $\ENUM{LOCK}$ entry may not yet be committed at the successor.
	It is possible to prevent this by introducing intermediate states $\bm{A}'$ and $\bm{E}'$, but it is not necessary to guarantee termination.
	Commands can be resent without resulting in duplicate entries as long as the tag remains the same.
	Thus, if a successor of a leader in state $\bm{A}$ or $\bm{E}$ is in state $\bm{L}'$, it will simply redo the commands for $\bm{L'} \rightarrow \bm{L}$ followed by $\bm{L} \rightarrow \bm{A}$ or $\bm{L} \rightarrow \bm{E}$.
	This is guaranteed to result in the same state as the predecessor, as two different command responses for the same tag are impossible by the properties of Raft.

	\section{Security analysis}
	The following is a security analysis of the algorithm described in section~\ref{sec:analysis}.

		\subsection{Adversary model}
		We allow for a very strong adversary that can coordinate faulty nodes, delay communication and delay correct nodes, but not indefinitely. 
		We assume that the adversary is computationally bound, so that they are probabilistically unable to subvert the cryptographic techniques described above.
		We also assume that the adversary does not have access to our cryptographic secrets.
		These include the shared common secret between the processes of the network, but also the processor specific PID key provisioned by Intel, as well as the associated group private keys stored by Intel.
		This is a quite strong assumption, in that Intel might be required surrender these keys by law in some countries.
		
		\subsection{Analysis}
		%if adv. takes over 1 process
		%	- At most channel failures
		%If adv. takes over $\leq$ f processes => f crashes/channel failures
		%	- Raft still works
		%If adv. takes over $>$ f processes => $>$ f crashes/channel failures
		%	- Safety still guaranteed, and some availability
		
		%Special cases:
		%If adv. takes over 2 processes in same cluser => liveness
		%	- fixed
		%If adv. takes over leader and stops client requests
		%	- eventual leader change / can be fixed by broadcast


	\section{DCR-TEE Implementation}

	\section{Distributed Smart Contract Engine}

	\section{Discussion}

		\subsection{SGX security}
		All aforementioned hardware guarantees are given by Intel, but since very little of the proprietary technology is documented, all security properties of SGX rely on the correctness of Intel's hardware implementation.
		Historically Intel has had vulnerabilities in similar hardware components, like the CVE-2017-5689 security incident exposed in~\cite{silent_bob}, allowed unprivileged access to the Intel Active Management Technology.

		SGX claims to provide confidentiality and integrity for running enclaves.
		This is ensured by preventing untrusted software access to the PRM and enclaves access to other regions of the PRM besides their exclusive region.
		However, while it is not possible to breach the integrity of PRM,~\cite{costan_intel_2016} shows several issues regarding confidentiality.
		Because enclaves use the system page table even for data residing on PRM, it is possible for untrusted software to learn the page access order by manipulating the OS controlled page table.
		Another possible attack vector is to perform cache timing by cleverly choosing the physical memory position of enclave memory pages on set associative caches.
		By mapping snooping software to the same cache set as the enclave, the snooping software can evict the enclave's memory from the cache and use timing to figure out if it is accessed again.
		Lastly, processors with hyper-threading support are vulnerable to instruction snooping, as a snooping process sharing physical core with an enclave can use performance counters to determine which instructions the out-of-order scheduler is able to run in parallel with the enclave.
		The presence of these attacks means that enclaves using data-dependent memory access will likely not ensure confidentiality.
		However, to our knowledge, no publicly known vulnerabilities exist on the integrity guarantee. 
		And since our system has very few confidentiality requirements, the known vulnerabilities do not seem problematic for the purposes of this project.

		As mentioned SGX does not protect against flawed software, so it is up to the developer to prevent side-channel attacks through OCALLs that might expose secret data.
		A noteworthy mention to illustrate the vigor needed is the common pitfall mentioned in~\cite{intel_sgx_guide} when using ECALLs and OCALLs.
		Because enclaves are compiled using a standard \cpp-compiler, structure padding is likely to happen.
		The SGX environment does not protect against leaking secret information through uninitialized structure padding when passing structures in ECALLs and OCALLs -- this, and other common security pitfalls, are not part of any SGX security guarantees.
		Intel recommends to always clear secrets from the enclave memory after use in~\cite{intel_sgx_guide}, regardless of the guarantees given by the PRM, underlining the risk of unintended vulnerabilities.

	\section{Conclusion}

	\subsection{Future Works}

	% \subsection{Network topology}
	% Due to the algorithm not requiring the executioner of an event to have the global state of the workflow at the time of execution, any state changes are only propagated to the relevant parties.
	% This means that any single crash could potentially make collecting the global state, or history of executions, impossible, as the localized state of the crashed peer would be lost.
	% To make the system more tolerant to crashes, the state of each event is tracked by a number of peers.
	% This means that all locks need to be made on a subsystem rather than a single peer.
	% As this lock needs to prevent others from locking simultaneously, $\dfrac{m}{2} +1$ locks are required for each peer, where $m$ is the number of peers tracking the state of that event.

	% \subsubsection{Peer distribution}
	% Given that the relations of a workflow are fixed at creation, the peers can be distributed efficiently by assigning events frequently locked simultaneously to the same peers.
	% This can be accomplished by the following steps:
	% \begin{itemize}
	%   \item Each event is assigned a set of peers, called the primaries of that event, containing at least one peer.
	%   \item The primaries of each event are added to each event on which the execution of the event tracked by the primaries could incur a lock. The peers added this way are called secondaries for that event.
	% \end{itemize}

	% The peer-to-peer network is then configured in such a way that each peer is a neighbour to any peer which tracks the same events.
	% This means that the execution of an event can be performed by a primary, by that primary attempting to lock all of its neighbours and checking whether or not the acquired locks are sufficient in order to perform the execution, meaning that the set of locked peers forms a quorum for each event requiring a lock.

	% Crash recovery

	% \subsection{Message composition}
	% In order to reduce the amount of messages needed in the system, the locking of an event can incorporate. 

	\newpage
	\bibliography{bibliography}{}
	\bibliographystyle{plain}

	\newpage

	\appendix

\end{document}
